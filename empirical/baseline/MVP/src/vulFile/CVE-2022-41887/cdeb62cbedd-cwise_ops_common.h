























namespace tensorflow {

typedef Eigen::ThreadPoolDevice CPUDevice;
typedef Eigen::GpuDevice GPUDevice;

class BinaryOpShared : public OpKernel {
 public:
  explicit BinaryOpShared(OpKernelConstruction* ctx, DataType out, DataType in);

 protected:
  struct BinaryOpState {
    
    
    
    
    
    
    explicit BinaryOpState(OpKernelContext* ctx);

    const Tensor& in0;
    const Tensor& in1;

    BCast bcast;
    Tensor* out = nullptr;
    int64_t out_num_elements;

    int64_t in0_num_elements;
    int64_t in1_num_elements;

    int ndims;
    bool result;
  };

  void SetUnimplementedError(OpKernelContext* ctx);
  void SetComputeError(OpKernelContext* ctx);
};




template <typename Device, typename Functor> class BinaryOp : public BinaryOpShared {
 public:
  typedef typename Functor::in_type Tin;    
  typedef typename Functor::out_type Tout;  

  explicit BinaryOp(OpKernelConstruction* ctx)
      : BinaryOpShared(ctx, DataTypeToEnum<Tout>::v(), DataTypeToEnum<Tin>::v()) {}

  void Compute(OpKernelContext* ctx) override {
    const Tensor& input_0 = ctx->input(0);
    OP_REQUIRES(ctx, input_0.dtype() == DataTypeToEnum<Tin>::v(), errors::InvalidArgument( "Expected tensor of type ", DataTypeString(DataTypeToEnum<Tin>::v()), " but got type ", DataTypeString(input_0.dtype())));



    const Tensor& input_1 = ctx->input(1);
    OP_REQUIRES(ctx, input_1.dtype() == DataTypeToEnum<Tin>::v(), errors::InvalidArgument( "Expected tensor of type ", DataTypeString(DataTypeToEnum<Tin>::v()), " but got type ", DataTypeString(input_1.dtype())));



    const Device& eigen_device = ctx->eigen_device<Device>();
    bool error = false;
    bool* const error_ptr = Functor::has_errors ? &error : nullptr;

    
    
    if (input_0.shape() == input_1.shape()) {
      
      Tensor* out;
      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output( {0, 1}, 0, input_0.shape(), &out));
      functor::BinaryFunctor<Device, Functor, 1>()( eigen_device, out->template flat<Tout>(), input_0.template flat<Tin>(), input_1.template flat<Tin>(), error_ptr);


      if (Functor::has_errors && error) {
        SetComputeError(ctx);
      }
      return;
    } else if (input_0.shape().dims() == 0) {
      
      Tensor* out;
      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output( {1}, 0, input_1.shape(), &out));

      functor::BinaryFunctor<Device, Functor, 1>().Left( eigen_device, out->template flat<Tout>(), input_0.template scalar<Tin>(), input_1.template flat<Tin>(), error_ptr);


      if (Functor::has_errors && error) {
        SetComputeError(ctx);
      }
      return;
    } else if (input_1.shape().dims() == 0) {
      
      Tensor* out;
      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output( {0}, 0, input_0.shape(), &out));
      functor::BinaryFunctor<Device, Functor, 1>().Right( eigen_device, out->template flat<Tout>(), input_0.template flat<Tin>(), input_1.template scalar<Tin>(), error_ptr);


      if (Functor::has_errors && error) {
        SetComputeError(ctx);
      }
      return;
    }

    
    BinaryOpState state(ctx);
    if (ctx->status().code() == error::RESOURCE_EXHAUSTED) {
      
      return;
    }
    auto& bcast = state.bcast;
    Tensor* out = state.out;
    if (!bcast.IsValid()) {
      if (ctx->status().ok()) {
        if (state.result) {
          functor::SetOneFunctor<Device, bool>()(eigen_device, out->flat<bool>());
        } else {
          functor::SetZeroFunctor<Device, bool>()(eigen_device, out->flat<bool>());
        }
      }
      return;
    }

    auto& in0 = state.in0;
    auto& in1 = state.in1;
    if (state.out_num_elements == 0) {
      return;
    }

    const int ndims = state.ndims;
    if (ndims <= 1) {
      auto out_flat = out->flat<Tout>();
      if (state.in1_num_elements == 1) {
        
        functor::BinaryFunctor<Device, Functor, 1>().Right( eigen_device, out_flat, in0.template flat<Tin>(), in1.template scalar<Tin>(), error_ptr);

      } else if (state.in0_num_elements == 1) {
        
        functor::BinaryFunctor<Device, Functor, 1>().Left( eigen_device, out_flat, in0.template scalar<Tin>(), in1.template flat<Tin>(), error_ptr);

      } else {
        functor::BinaryFunctor<Device, Functor, 1>()( eigen_device, out_flat, in0.template flat<Tin>(), in1.template flat<Tin>(), error_ptr);

      }
    } else if (ndims == 2) {
      functor::BinaryFunctor<Device, Functor, 2>().BCast( eigen_device, out->shaped<Tout, 2>(bcast.result_shape()), in0.template shaped<Tin, 2>(bcast.x_reshape()), BCast::ToIndexArray<2>(bcast.x_bcast()), in1.template shaped<Tin, 2>(bcast.y_reshape()), BCast::ToIndexArray<2>(bcast.y_bcast()), error_ptr);




    } else if (ndims == 3) {
      functor::BinaryFunctor<Device, Functor, 3>().BCast( eigen_device, out->shaped<Tout, 3>(bcast.result_shape()), in0.template shaped<Tin, 3>(bcast.x_reshape()), BCast::ToIndexArray<3>(bcast.x_bcast()), in1.template shaped<Tin, 3>(bcast.y_reshape()), BCast::ToIndexArray<3>(bcast.y_bcast()), error_ptr);




    } else if (ndims == 4) {
      functor::BinaryFunctor<Device, Functor, 4>().BCast( eigen_device, out->shaped<Tout, 4>(bcast.result_shape()), in0.template shaped<Tin, 4>(bcast.x_reshape()), BCast::ToIndexArray<4>(bcast.x_bcast()), in1.template shaped<Tin, 4>(bcast.y_reshape()), BCast::ToIndexArray<4>(bcast.y_bcast()), error_ptr);




    } else if (ndims == 5) {
      functor::BinaryFunctor<Device, Functor, 5>().BCast( eigen_device, out->shaped<Tout, 5>(bcast.result_shape()), in0.template shaped<Tin, 5>(bcast.x_reshape()), BCast::ToIndexArray<5>(bcast.x_bcast()), in1.template shaped<Tin, 5>(bcast.y_reshape()), BCast::ToIndexArray<5>(bcast.y_bcast()), error_ptr);




    } else {
      SetUnimplementedError(ctx);
    }
    if (Functor::has_errors && error) {
      SetComputeError(ctx);
    }
  }
};

template <typename Device, typename T> class ApproximateEqualOp : public OpKernel {
 public:
  explicit ApproximateEqualOp(OpKernelConstruction* context)
      : OpKernel(context) {
    float tolerance;
    OP_REQUIRES_OK(context, context->GetAttr("tolerance", &tolerance));
    tolerance_ = T(tolerance);
  }
  void Compute(OpKernelContext* context) override {
    const Tensor& x_input = context->input(0);
    const Tensor& y_input = context->input(1);
    OP_REQUIRES( context, x_input.shape() == y_input.shape(), errors::InvalidArgument("x and y must be of the same shape. ", "x shape: ", x_input.shape().DebugString(), ". y shape: ", y_input.shape().DebugString()));



    Tensor* z_output = nullptr;
    OP_REQUIRES_OK(context, context->allocate_output(0, x_input.shape(), &z_output));
    const Device& d = context->eigen_device<Device>();
    typename TTypes<T>::ConstFlat x(x_input.flat<T>());
    typename TTypes<T>::ConstFlat y(y_input.flat<T>());
    typename TTypes<bool>::Flat z(z_output->flat<bool>());
    functor::ApproximateEqual<Device, T>()(d, x, y, tolerance_, z);
  }

 private:
  T tolerance_;
};






template <typename Device, typename Functor> class SimpleBinaryOp : public OpKernel {
 public:
  typedef typename Functor::in_type Tin;    
  typedef typename Functor::out_type Tout;  

  explicit SimpleBinaryOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}

  void Compute(OpKernelContext* ctx) override {
    const Tensor& in0 = ctx->input(0);
    const Tensor& in1 = ctx->input(1);
    OP_REQUIRES( ctx, in0.NumElements() == in1.NumElements(), errors::InvalidArgument("The two arguments to a cwise op must have " "same number of elements, got ", in0.NumElements(), " and ", in1.NumElements()));



    auto in0_flat = in0.flat<Tin>();
    auto in1_flat = in1.flat<Tin>();
    const Device& eigen_device = ctx->eigen_device<Device>();

    Tensor* out = nullptr;
    if (std::is_same<Tin, Tout>::value) {
      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output( {0, 1}, 0, in0.shape(), &out));
    } else {
      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, in0.shape(), &out));
    }
    auto out_flat = out->flat<Tout>();
    functor::SimpleBinaryFunctor<Device, Functor>()(eigen_device, out_flat, in0_flat, in1_flat);
  }
};




template <typename Device, typename Functor> class UnaryOp : public OpKernel {
 public:
  typedef typename Functor::in_type Tin;    
  typedef typename Functor::out_type Tout;  
  

  explicit UnaryOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
    auto in = DataTypeToEnum<Tin>::v();
    auto out = DataTypeToEnum<Tout>::v();
    OP_REQUIRES_OK(ctx, ctx->MatchSignature({in}, {out}));
  }

  void Compute(OpKernelContext* ctx) override {
    const Tensor& inp = ctx->input(0);
    Tensor* out = nullptr;
    if (std::is_same<Tin, Tout>::value) {
      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output( {0}, 0, inp.shape(), &out));
    } else {
      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, inp.shape(), &out));
    }
    functor::UnaryFunctor<Device, Functor>()( ctx->eigen_device<Device>(), out->flat<Tout>(), inp.flat<Tin>());
  }
};

template <typename Device, VariantUnaryOp OpEnum> class UnaryVariantOp : public OpKernel {
 public:
  explicit UnaryVariantOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}

  void Compute(OpKernelContext* ctx) override {
    const Tensor& inp = ctx->input(0);
    OP_REQUIRES( ctx, TensorShapeUtils::IsScalar(inp.shape()), errors::InvalidArgument("Non-scalar variants are not supported."));

    const Variant& v = inp.scalar<Variant>()();
    Variant v_out;
    OP_REQUIRES_OK(ctx, UnaryOpVariant<Device>(ctx, OpEnum, v, &v_out));
    int numa_node = ctx->device()->NumaNode();
    Tensor out(cpu_allocator(numa_node), DT_VARIANT, TensorShape());
    out.scalar<Variant>()() = std::move(v_out);
    ctx->set_output(0, std::move(out));
  }
};

namespace functor {

template <typename D, typename Out, typename Rhs> void Assign(const D& d, Out out, Rhs rhs) {
  out.device(d) = rhs;
}



template <typename Functor, int NDIMS> struct BinaryFunctor<CPUDevice, Functor, NDIMS, false> {
  void operator()(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in0, typename Functor::tin_type in1, bool* error) {

    Assign(d, out, in0.binaryExpr(in1, typename Functor::func()));
  }

  void Left(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tscalar_type scalar, typename Functor::tin_type in, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_left<Tout, Tin, Binary, true> Unary;


    Assign(d, out, in.unaryExpr(Unary(scalar.data())));
  }

  void Right(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in, typename Functor::tscalar_type scalar, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_right< Tout, Tin, Binary, true> Unary;

    Assign(d, out, in.unaryExpr(Unary(scalar.data())));
  }

  void BCast(const CPUDevice& dev, typename TTypes<typename Functor::out_type, NDIMS>::Tensor out, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in0, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast0, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in1, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast1, bool* error) {





    typename Functor::func func;
    if (AllOne<NDIMS>(bcast0) && AllOne<NDIMS>(bcast1)) {
      Assign(dev, out, in0.binaryExpr(in1, func));
    } else if (AllOne<NDIMS>(bcast0)) {
      auto rhs = in1.broadcast(bcast1);
      Assign(dev, out, in0.binaryExpr(rhs, func));
    } else if (AllOne<NDIMS>(bcast1)) {
      auto lhs = in0.broadcast(bcast0);
      Assign(dev, out, lhs.binaryExpr(in1, func));
    } else {
      auto lhs = in0.broadcast(bcast0);
      auto rhs = in1.broadcast(bcast1);
      Assign(dev, out, lhs.binaryExpr(rhs, func));
    }
  }
};



template <typename Functor> struct BinaryFunctor<CPUDevice, Functor, 2, false> {
  enum { NDIMS = 2 };

  void operator()(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in0, typename Functor::tin_type in1, bool* error) {

    Assign(d, out, in0.binaryExpr(in1, typename Functor::func()));
  }

  void Left(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tscalar_type scalar, typename Functor::tin_type in, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_left<Tout, Tin, Binary, true> Unary;


    Assign(d, out, in.unaryExpr(Unary(scalar.data())));
  }

  void Right(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in, typename Functor::tscalar_type scalar, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_right< Tout, Tin, Binary, true> Unary;

    Assign(d, out, in.unaryExpr(Unary(scalar.data())));
  }

  inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {
    Eigen::IndexList<int, Eigen::type2index<1>> ret;
    ret.set(0, n);
    return ret;
  }
  inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {
    Eigen::IndexList<Eigen::type2index<1>, int> ret;
    ret.set(1, m);
    return ret;
  }

  void BCast(const CPUDevice& dev, typename TTypes<typename Functor::out_type, NDIMS>::Tensor out, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in0, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast0, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in1, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast1, bool* error) {





    typedef typename Functor::in_type T;
    typename Functor::func func;
    if (Functor::use_bcast_optimization && use_bcast_optimization<T>::value) {
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      const int a = in0.dimension(0);  
      const int b = in0.dimension(1);
      const int c = in1.dimension(0);  
      const int d = in1.dimension(1);
      if ((a == 1) && (d == 1)) {
        auto lhs = in0.reshape(OneByM(b)).broadcast(NByOne(c));
        auto rhs = in1.reshape(NByOne(c)).broadcast(OneByM(b));
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
      if ((b == 1) && (c == 1)) {
        auto lhs = in0.reshape(NByOne(a)).broadcast(OneByM(d));
        auto rhs = in1.reshape(OneByM(d)).broadcast(NByOne(a));
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
      if (a == 1) {
        auto lhs = in0.reshape(OneByM(b)).broadcast(NByOne(c));
        auto rhs = in1;
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
      if (b == 1) {
        auto lhs = in0.reshape(NByOne(a)).broadcast(OneByM(d));
        auto rhs = in1;
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
      if (c == 1) {
        auto lhs = in0;
        auto rhs = in1.reshape(OneByM(d)).broadcast(NByOne(a));
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
      if (d == 1) {
        auto lhs = in0;
        auto rhs = in1.reshape(NByOne(c)).broadcast(OneByM(b));
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }

      const bool bcast0_all_one = AllOne<NDIMS>(bcast0);
      const bool bcast1_all_one = AllOne<NDIMS>(bcast1);
      if (bcast0_all_one && !bcast1_all_one) {
        auto lhs = in0;  
        auto rhs = in1.broadcast(bcast1);
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }

      if (!bcast0_all_one && bcast1_all_one) {
        auto lhs = in0.broadcast(bcast0);
        auto rhs = in1;  
        Assign(dev, out, lhs.binaryExpr(rhs, func));
        return;
      }
    }

    
    auto lhs = in0.broadcast(bcast0);
    auto rhs = in1.broadcast(bcast1);
    Assign(dev, out, lhs.binaryExpr(rhs, func));
  }
};


template <typename Functor, int NDIMS> struct BinaryFunctor<CPUDevice, Functor, NDIMS, true> {
  void operator()(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in0, typename Functor::tin_type in1, bool* error) {

    Assign(d, out, in0.binaryExpr(in1, typename Functor::func(error)));
  }

  void Left(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tscalar_type scalar, typename Functor::tin_type in, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_left<Tout, Tin, Binary, true> Unary;


    Assign(d, out, in.unaryExpr(Unary(scalar.data(), error)));
  }

  void Right(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in, typename Functor::tscalar_type scalar, bool* error) {

    typedef typename Functor::out_type Tout;
    typedef typename Functor::in_type Tin;
    typedef typename Functor::func Binary;
    typedef typename Eigen::internal::scalar_right< Tout, Tin, Binary, true> Unary;

    Assign(d, out, in.unaryExpr(Unary(scalar.data(), error)));
  }

  void BCast(const CPUDevice& dev, typename TTypes<typename Functor::out_type, NDIMS>::Tensor out, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in0, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast0, typename TTypes<typename Functor::in_type, NDIMS>::ConstTensor in1, typename Eigen::array<Eigen::DenseIndex, NDIMS> bcast1, bool* error) {





    typename Functor::func func(error);
    auto lhs = in0.broadcast(bcast0);
    auto rhs = in1.broadcast(bcast1);
    Assign(dev, out, lhs.binaryExpr(rhs, func));
  }
};


template <typename Functor> struct UnaryFunctor<CPUDevice, Functor> {
  void operator()(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in) {
    Assign(d, out, in.unaryExpr(typename Functor::func()));
  }
};

template <typename Functor, typename Targ> struct UnaryFunctorWithArg<CPUDevice, Functor, Targ> {
  void operator()(const CPUDevice& d, typename Functor::tout_type out, typename Functor::tin_type in, Targ val) {
    Assign(d, out, in.unaryExpr(typename Functor::func(val)));
  }
};


template <typename T> struct ApproximateEqual<CPUDevice, T> {
  void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat x, typename TTypes<T>::ConstFlat y, T tolerance, typename TTypes<bool>::Flat z) {

    auto diff = x - y;
    z.device(d) = diff.abs() <= tolerance;
  }
};

}  

















































}  


