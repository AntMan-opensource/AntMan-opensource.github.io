












extern "C" {



void *untrusted_cache_malloc(size_t size) {
  asylo::UntrustedCacheMalloc *instance = asylo::UntrustedCacheMalloc::Instance();
  return instance->Malloc(size);
}

void untrusted_cache_free(void *buffer) {
  asylo::UntrustedCacheMalloc *instance = asylo::UntrustedCacheMalloc::Instance();
  instance->Free(buffer);
}

}  

namespace asylo {

using primitives::TrustedPrimitives;

bool UntrustedCacheMalloc::is_destroyed_ = false;

UntrustedCacheMalloc *UntrustedCacheMalloc::Instance() {
  static TrustedSpinLock lock(false);
  static UntrustedCacheMalloc *instance = nullptr;
  if (instance == nullptr) {
    LockGuard guard(&lock);
    if (instance == nullptr) {
      instance = new UntrustedCacheMalloc();
    }
  }
  return instance;
}

UntrustedCacheMalloc::UntrustedCacheMalloc() : lock_(true) {
  if (is_destroyed_) {
    return;
  }
  
  
  free_list_ = absl::make_unique<FreeList>();
  free_list_->buffers.reset(reinterpret_cast<void **>( primitives::TrustedPrimitives::UntrustedLocalAlloc(sizeof(void *) * kFreeListCapacity)));

  free_list_->count = 0;
}

UntrustedCacheMalloc::~UntrustedCacheMalloc() {
  while (!buffer_pool_.empty()) {
    PushToFreeList(buffer_pool_.top());
    buffer_pool_.pop();
  }

  
  
  
  if (free_list_->count > 0) {
    primitives::DeAllocateUntrustedBuffers(free_list_->buffers.get(), free_list_->count);
  }
  is_destroyed_ = true;
}

void *UntrustedCacheMalloc::GetBuffer() {
  void **buffers = nullptr;
  void *buffer;
  bool is_pool_empty;

  {
    LockGuard spin_lock(&lock_);
    is_pool_empty = buffer_pool_.empty();
    if (is_pool_empty) {
      buffers = primitives::AllocateUntrustedBuffers(kPoolIncrement, kPoolEntrySize);
      for (int i = 0; i < kPoolIncrement; i++) {
        if (!buffers[i] || !TrustedPrimitives::IsOutsideEnclave(buffers[i], kPoolEntrySize)) {
          abort();
        }
        buffer_pool_.push(buffers[i]);
      }
    }
    buffer = buffer_pool_.top();
    buffer_pool_.pop();
    busy_buffers_.insert(buffer);
  }

  if (is_pool_empty) {
    
    
    Free(buffers);
  }
  return buffer;
}

void *UntrustedCacheMalloc::Malloc(size_t size) {
  
  
  
  if (is_destroyed_ || (size > kPoolEntrySize) || GetSwitchedHeapNext()) {
    return primitives::TrustedPrimitives::UntrustedLocalAlloc(size);
  }
  return GetBuffer();
}

void UntrustedCacheMalloc::PushToFreeList(void *buffer) {
  free_list_->buffers.get()[free_list_->count] = buffer;
  free_list_->count++;

  if (free_list_->count == kFreeListCapacity) {
    primitives::DeAllocateUntrustedBuffers(free_list_->buffers.get(), kFreeListCapacity);
    free_list_->count = 0;
  }
}

void UntrustedCacheMalloc::Free(void *buffer) {
  if (is_destroyed_ || GetSwitchedHeapNext()) {
    primitives::TrustedPrimitives::UntrustedLocalFree(buffer);
    return;
  }
  LockGuard spin_lock(&lock_);

  
  
  
  if (busy_buffers_.find(buffer) == busy_buffers_.end()) {
    PushToFreeList(buffer);
    return;
  }
  busy_buffers_.erase(buffer);
  buffer_pool_.push(buffer);
}

}  
