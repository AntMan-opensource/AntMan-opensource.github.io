



























































































static const float kPacingGain[] = {1.25, 0.75, 1, 1, 1, 1, 1, 1};


static const size_t kGainCycleLength = sizeof(kPacingGain)
                                                    / sizeof(kPacingGain[0]);


































static uint64_t lsquic_bbr_get_cwnd (void *);


static const char *const mode2str[] = {
    [BBR_MODE_STARTUP]   = "STARTUP", [BBR_MODE_DRAIN]     = "DRAIN", [BBR_MODE_PROBE_BW]  = "PROBE_BW", [BBR_MODE_PROBE_RTT] = "PROBE_RTT", };





static void set_mode (struct lsquic_bbr *bbr, enum bbr_mode mode)
{
    if (bbr->bbr_mode != mode)
    {
        LSQ_DEBUG("mode change %s -> %s", mode2str[bbr->bbr_mode], mode2str[mode]);
        bbr->bbr_mode = mode;
    }
    else LSQ_DEBUG("mode remains %s", mode2str[mode]);
}


static void set_startup_values (struct lsquic_bbr *bbr)
{
    bbr->bbr_pacing_gain = bbr->bbr_high_gain;
    bbr->bbr_cwnd_gain = bbr->bbr_high_cwnd_gain;
}


static void init_bbr (struct lsquic_bbr *bbr)
{
    bbr->bbr_mode = BBR_MODE_STARTUP;
    bbr->bbr_round_count = 0;
    minmax_init(&bbr->bbr_max_bandwidth, 10);
    minmax_init(&bbr->bbr_max_ack_height, 10);
    bbr->bbr_aggregation_epoch_bytes = 0;
    bbr->bbr_aggregation_epoch_start_time = 0;
    bbr->bbr_min_rtt = 0;
    bbr->bbr_min_rtt_timestamp = 0;
    bbr->bbr_init_cwnd = kInitialCongestionWindow * kDefaultTCPMSS;
    bbr->bbr_cwnd = kInitialCongestionWindow * kDefaultTCPMSS;
    bbr->bbr_max_cwnd = kDefaultMaxCongestionWindowPackets * kDefaultTCPMSS;
    bbr->bbr_min_cwnd = kDefaultMinimumCongestionWindow;
    bbr->bbr_high_gain = kDefaultHighGain;
    bbr->bbr_high_cwnd_gain = kDefaultHighGain;
    bbr->bbr_drain_gain = 1.0f / kDefaultHighGain;
    bbr->bbr_pacing_rate = BW_ZERO();
    bbr->bbr_pacing_gain = 1.0;
    bbr->bbr_cwnd_gain = 1.0;
    bbr->bbr_num_startup_rtts = kRoundTripsWithoutGrowthBeforeExitingStartup;
    bbr->bbr_flags &= ~BBR_FLAG_EXIT_STARTUP_ON_LOSS;
    bbr->bbr_cycle_current_offset = 0;
    bbr->bbr_last_cycle_start = 0;
    bbr->bbr_flags &= ~BBR_FLAG_IS_AT_FULL_BANDWIDTH;
    bbr->bbr_round_wo_bw_gain = 0;
    bbr->bbr_bw_at_last_round = BW_ZERO();
    bbr->bbr_flags &= ~BBR_FLAG_EXITING_QUIESCENCE;
    bbr->bbr_exit_probe_rtt_at = 0;
    bbr->bbr_flags &= ~BBR_FLAG_PROBE_RTT_ROUND_PASSED;
    bbr->bbr_flags &= ~BBR_FLAG_LAST_SAMPLE_APP_LIMITED;
    bbr->bbr_flags &= ~BBR_FLAG_HAS_NON_APP_LIMITED;
    bbr->bbr_flags &= ~BBR_FLAG_FLEXIBLE_APP_LIMITED;
    set_startup_values(bbr);
}


static void lsquic_bbr_init (void *cong_ctl, const struct lsquic_conn_public *conn_pub, enum quic_ft_bit retx_frames)

{
    struct lsquic_bbr *const bbr = cong_ctl;
    bbr->bbr_conn_pub = conn_pub;
    lsquic_bw_sampler_init(&bbr->bbr_bw_sampler, conn_pub->lconn, retx_frames);
    bbr->bbr_rtt_stats = &conn_pub->rtt_stats;

    init_bbr(bbr);

    LSQ_DEBUG("initialized");
}


static void lsquic_bbr_reinit (void *cong_ctl)
{
    struct lsquic_bbr *const bbr = cong_ctl;

    init_bbr(bbr);

    LSQ_DEBUG("re-initialized");
}


static lsquic_time_t get_min_rtt (const struct lsquic_bbr *bbr)
{
    lsquic_time_t min_rtt;

    if (bbr->bbr_min_rtt)
        return bbr->bbr_min_rtt;
    else {
        min_rtt = lsquic_rtt_stats_get_min_rtt(bbr->bbr_rtt_stats);
        if (min_rtt == 0)
            min_rtt = 25000;
        return min_rtt;
    }
}


static uint64_t lsquic_bbr_pacing_rate (void *cong_ctl, int in_recovery)
{
    struct lsquic_bbr *const bbr = cong_ctl;
    lsquic_time_t min_rtt;
    struct bandwidth bw;

    if (!BW_IS_ZERO(&bbr->bbr_pacing_rate))
        bw = bbr->bbr_pacing_rate;
    else {
        min_rtt = get_min_rtt(bbr);
        bw = BW_FROM_BYTES_AND_DELTA(bbr->bbr_init_cwnd, min_rtt);
        bw = BW_TIMES(&bw, bbr->bbr_high_cwnd_gain);
    }

    return BW_TO_BYTES_PER_SEC(&bw);
}



static uint64_t get_target_cwnd (const struct lsquic_bbr *bbr, float gain)
{
    struct bandwidth bw;
    uint64_t bdp, cwnd;

    bw = BW(minmax_get(&bbr->bbr_max_bandwidth));
    bdp = get_min_rtt(bbr) * BW_TO_BYTES_PER_SEC(&bw) / 1000000;
    cwnd = gain * bdp;

    
    if (cwnd == 0)
        cwnd = gain * bbr->bbr_init_cwnd;

    return MAX(cwnd, bbr->bbr_min_cwnd);
}



static int is_pipe_sufficiently_full (struct lsquic_bbr *bbr, uint64_t bytes_in_flight)
{
    
    if (bbr->bbr_mode == BBR_MODE_STARTUP)
        
        
        return bytes_in_flight >= get_target_cwnd(bbr, 1.5);
    else if (bbr->bbr_pacing_gain > 1)
        
        return bytes_in_flight >= get_target_cwnd(bbr, bbr->bbr_pacing_gain);
    else   return bytes_in_flight >= get_target_cwnd(bbr, 1.1f);


}


static void lsquic_bbr_was_quiet (void *cong_ctl, lsquic_time_t now, uint64_t in_flight)
{
    struct lsquic_bbr *const bbr = cong_ctl;
    LSQ_DEBUG("was quiet");         
}



static void bbr_app_limited (struct lsquic_bbr *bbr, uint64_t bytes_in_flight)
{
    uint64_t cwnd;

    cwnd = lsquic_bbr_get_cwnd(bbr);
    if (bytes_in_flight >= cwnd)
        return;
    if ((bbr->bbr_flags & BBR_FLAG_FLEXIBLE_APP_LIMITED)
                            && is_pipe_sufficiently_full(bbr, bytes_in_flight))
        return;

    bbr->bbr_flags |= BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT;
    lsquic_bw_sampler_app_limited(&bbr->bbr_bw_sampler);
    LSQ_DEBUG("becoming application-limited.  Last sent packet: %"PRIu64"; " "CWND: %"PRIu64, bbr->bbr_last_sent_packno, cwnd);
}


static void lsquic_bbr_ack (void *cong_ctl, struct lsquic_packet_out *packet_out, unsigned packet_sz, lsquic_time_t now_time, int app_limited)

{
    struct lsquic_bbr *const bbr = cong_ctl;
    struct bw_sample *sample;

    assert(bbr->bbr_flags & BBR_FLAG_IN_ACK);

    sample = lsquic_bw_sampler_packet_acked(&bbr->bbr_bw_sampler, packet_out, bbr->bbr_ack_state.ack_time);
    if (sample)
        TAILQ_INSERT_TAIL(&bbr->bbr_ack_state.samples, sample, next);

    if (!is_valid_packno(bbr->bbr_ack_state.max_packno)
                
            || packet_out->po_packno > bbr->bbr_ack_state.max_packno)
        bbr->bbr_ack_state.max_packno = packet_out->po_packno;
    bbr->bbr_ack_state.acked_bytes += packet_sz;
}


static void lsquic_bbr_sent (void *cong_ctl, struct lsquic_packet_out *packet_out, uint64_t in_flight, int app_limited)

{
    struct lsquic_bbr *const bbr = cong_ctl;

    if (!(packet_out->po_flags & PO_MINI))
        lsquic_bw_sampler_packet_sent(&bbr->bbr_bw_sampler, packet_out, in_flight);

    
    bbr->bbr_last_sent_packno = packet_out->po_packno;

    if (app_limited)
        bbr_app_limited(bbr, in_flight);
}


static void lsquic_bbr_lost (void *cong_ctl, struct lsquic_packet_out *packet_out, unsigned packet_sz)

{
    struct lsquic_bbr *const bbr = cong_ctl;

    lsquic_bw_sampler_packet_lost(&bbr->bbr_bw_sampler, packet_out);
    bbr->bbr_ack_state.has_losses = 1;
    bbr->bbr_ack_state.lost_bytes += packet_sz;
}


static void lsquic_bbr_begin_ack (void *cong_ctl, lsquic_time_t ack_time, uint64_t in_flight)
{
    struct lsquic_bbr *const bbr = cong_ctl;

    assert(!(bbr->bbr_flags & BBR_FLAG_IN_ACK));
    bbr->bbr_flags |= BBR_FLAG_IN_ACK;
    memset(&bbr->bbr_ack_state, 0, sizeof(bbr->bbr_ack_state));
    TAILQ_INIT(&bbr->bbr_ack_state.samples);
    bbr->bbr_ack_state.ack_time = ack_time;
    bbr->bbr_ack_state.max_packno = UINT64_MAX;
    bbr->bbr_ack_state.in_flight = in_flight;
    bbr->bbr_ack_state.total_bytes_acked_before = lsquic_bw_sampler_total_acked(&bbr->bbr_bw_sampler);
}



static int should_extend_min_rtt_expiry (const struct lsquic_bbr *bbr)
{
    int increased_since_last_probe;

    if ((bbr->bbr_flags & (BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT |BBR_FLAG_PROBE_RTT_DISABLED_IF_APP_LIMITED))
            == (BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT |BBR_FLAG_PROBE_RTT_DISABLED_IF_APP_LIMITED))
        
        return 1;

    increased_since_last_probe = bbr->bbr_min_rtt_since_last_probe > bbr->bbr_min_rtt * kSimilarMinRttThreshold;
    if ((bbr->bbr_flags & (BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT |BBR_FLAG_PROBE_RTT_SKIPPED_IF_SIMILAR_RTT))
            == (BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT |BBR_FLAG_PROBE_RTT_SKIPPED_IF_SIMILAR_RTT)
            && !increased_since_last_probe)
        
        
        
        return 1;

    return 0;
}




static int update_bandwidth_and_min_rtt (struct lsquic_bbr *bbr)
{
    struct bw_sample *sample, *next_sample;
    uint64_t sample_min_rtt;
    int min_rtt_expired;

    sample_min_rtt = UINT64_MAX;
    for (sample = TAILQ_FIRST(&bbr->bbr_ack_state.samples); sample;
                                                        sample = next_sample)
    {
        next_sample = TAILQ_NEXT(sample, next);

        if (sample->is_app_limited)
            bbr->bbr_flags |= BBR_FLAG_LAST_SAMPLE_APP_LIMITED;
        else {
            bbr->bbr_flags &= ~BBR_FLAG_LAST_SAMPLE_APP_LIMITED;
            bbr->bbr_flags |=  BBR_FLAG_HAS_NON_APP_LIMITED;
        }

        if (sample_min_rtt == UINT64_MAX || sample->rtt < sample_min_rtt)
            sample_min_rtt = sample->rtt;

        if (!sample->is_app_limited || BW_VALUE(&sample->bandwidth)
                                    > minmax_get(&bbr->bbr_max_bandwidth))
            minmax_upmax(&bbr->bbr_max_bandwidth, bbr->bbr_round_count, BW_VALUE(&sample->bandwidth));

        lsquic_malo_put(sample);
    }

    if (sample_min_rtt == UINT64_MAX)
        return 0;

    bbr->bbr_min_rtt_since_last_probe = MIN(bbr->bbr_min_rtt_since_last_probe, sample_min_rtt);

    min_rtt_expired = bbr->bbr_min_rtt != 0 && (bbr->bbr_ack_state.ack_time > bbr->bbr_min_rtt_timestamp + kMinRttExpiry);
    if (min_rtt_expired || sample_min_rtt < bbr->bbr_min_rtt || 0 == bbr->bbr_min_rtt)
    {
        if (min_rtt_expired && should_extend_min_rtt_expiry(bbr))
        {
            LSQ_DEBUG("min rtt expiration extended, stay at: %"PRIu64, bbr->bbr_min_rtt);
            min_rtt_expired = 0;
        }
        else {
            LSQ_DEBUG("min rtt updated: %"PRIu64" -> %"PRIu64, bbr->bbr_min_rtt, sample_min_rtt);
            bbr->bbr_min_rtt = sample_min_rtt;
        }
        bbr->bbr_min_rtt_timestamp = bbr->bbr_ack_state.ack_time;
        bbr->bbr_min_rtt_since_last_probe = UINT64_MAX;
        bbr->bbr_flags &= ~BBR_FLAG_APP_LIMITED_SINCE_LAST_PROBE_RTT;
    }

    return min_rtt_expired;
}



static void update_recovery_state (struct lsquic_bbr *bbr, int is_round_start)
{
    
    if (bbr->bbr_ack_state.has_losses)
        bbr->bbr_end_recovery_at = bbr->bbr_last_sent_packno;

    switch (bbr->bbr_recovery_state)
    {
    case BBR_RS_NOT_IN_RECOVERY:
        
        if (bbr->bbr_ack_state.has_losses)
        {
            bbr->bbr_recovery_state = BBR_RS_CONSERVATION;
            
            
            bbr->bbr_recovery_window = 0;
            
            
            bbr->bbr_current_round_trip_end = bbr->bbr_last_sent_packno;
        }
        break;
    case BBR_RS_CONSERVATION:
        if (is_round_start)
            bbr->bbr_recovery_state = BBR_RS_GROWTH;
        
    case BBR_RS_GROWTH:
        
        if (!bbr->bbr_ack_state.has_losses && bbr->bbr_ack_state.max_packno > bbr->bbr_end_recovery_at)
            bbr->bbr_recovery_state = BBR_RS_NOT_IN_RECOVERY;
        break;
    }
}


static uint64_t update_ack_aggregation_bytes (struct lsquic_bbr *bbr, uint64_t newly_acked_bytes)

{
    const lsquic_time_t ack_time = bbr->bbr_ack_state.ack_time;
    uint64_t expected_bytes_acked, diff;

    
    
    expected_bytes_acked = minmax_get(&bbr->bbr_max_bandwidth)
                        * (ack_time - bbr->bbr_aggregation_epoch_start_time);

    
    
    if (bbr->bbr_aggregation_epoch_bytes <= expected_bytes_acked)
    {
        
        bbr->bbr_aggregation_epoch_bytes = newly_acked_bytes;
        bbr->bbr_aggregation_epoch_start_time = ack_time;
        return 0;
    }

    
    
    bbr->bbr_aggregation_epoch_bytes += newly_acked_bytes;
    diff = bbr->bbr_aggregation_epoch_bytes - expected_bytes_acked;
    minmax_upmax(&bbr->bbr_max_ack_height, bbr->bbr_round_count, diff);
    return diff;
}



static void update_gain_cycle_phase (struct lsquic_bbr *bbr, uint64_t bytes_in_flight)
{
    const uint64_t prior_in_flight = bbr->bbr_ack_state.in_flight;
    const lsquic_time_t now = bbr->bbr_ack_state.ack_time;
    
    int should_advance_gain_cycling = now - bbr->bbr_last_cycle_start > get_min_rtt(bbr);

    
    
    
    
    
    if (bbr->bbr_pacing_gain > 1.0 && !bbr->bbr_ack_state.has_losses && prior_in_flight < get_target_cwnd(bbr, bbr->bbr_pacing_gain))

        should_advance_gain_cycling = 0;

    

    
    
    
    
    
    if (bbr->bbr_pacing_gain < 1.0 && bytes_in_flight <= get_target_cwnd(bbr, 1))
        should_advance_gain_cycling = 1;

    if (should_advance_gain_cycling)
    {
        bbr->bbr_cycle_current_offset = (bbr->bbr_cycle_current_offset + 1) % kGainCycleLength;
        bbr->bbr_last_cycle_start = now;
        
        
        if ((bbr->bbr_flags & BBR_FLAG_DRAIN_TO_TARGET)
                && bbr->bbr_pacing_gain < 1 && kPacingGain[bbr->bbr_cycle_current_offset] == 1 && bytes_in_flight > get_target_cwnd(bbr, 1))

              return;
        bbr->bbr_pacing_gain = kPacingGain[bbr->bbr_cycle_current_offset];
        LSQ_DEBUG("advanced gain cycle, pacing gain set to %.2f", bbr->bbr_pacing_gain);
    }
}



static int in_recovery (const struct lsquic_bbr *bbr)
{
    return bbr->bbr_recovery_state != BBR_RS_NOT_IN_RECOVERY;
}



static void check_if_full_bw_reached (struct lsquic_bbr *bbr)
{
    struct bandwidth target, bw;

    if (bbr->bbr_flags & BBR_FLAG_LAST_SAMPLE_APP_LIMITED)
    {
        LSQ_DEBUG("last sample app limited: full BW not reached");
        return;
    }

    target = BW_TIMES(&bbr->bbr_bw_at_last_round, kStartupGrowthTarget);
    bw = BW(minmax_get(&bbr->bbr_max_bandwidth));
    if (BW_VALUE(&bw) >= BW_VALUE(&target))
    {
        bbr->bbr_bw_at_last_round = bw;
        bbr->bbr_round_wo_bw_gain = 0;
        if (bbr->bbr_flags & BBR_FLAG_EXPIRE_ACK_AGG_IN_STARTUP)
            
            
            minmax_reset(&bbr->bbr_max_ack_height, ((struct minmax_sample) { bbr->bbr_round_count, 0, }));
        LSQ_DEBUG("BW estimate %"PRIu64"bps greater than or equal to target " "%"PRIu64"bps: full BW not reached", BW_VALUE(&bw), BW_VALUE(&target));

        return;
    }

    ++bbr->bbr_round_wo_bw_gain;
    if ((bbr->bbr_round_wo_bw_gain >= bbr->bbr_num_startup_rtts)
            || ((bbr->bbr_flags & BBR_FLAG_EXIT_STARTUP_ON_LOSS)
                                                    && in_recovery(bbr)))
    {
        assert(bbr->bbr_flags & BBR_FLAG_HAS_NON_APP_LIMITED);  
        bbr->bbr_flags |= BBR_FLAG_IS_AT_FULL_BANDWIDTH;
        LSQ_DEBUG("reached full BW");
    }
    else LSQ_DEBUG("rounds w/o gain: %u, full BW not reached", bbr->bbr_round_wo_bw_gain);

}



static void on_exit_startup (struct lsquic_bbr *bbr, lsquic_time_t now)
{
    assert(bbr->bbr_mode == BBR_MODE_STARTUP);
    
}



static void enter_probe_bw_mode (struct lsquic_bbr *bbr, lsquic_time_t now)
{
    uint8_t rand;

    set_mode(bbr, BBR_MODE_PROBE_BW);
    bbr->bbr_cwnd_gain = kCwndGain;

    
    
    
    rand = lsquic_crand_get_byte(bbr->bbr_conn_pub->enpub->enp_crand);
    bbr->bbr_cycle_current_offset = rand % (kGainCycleLength - 1);
    if (bbr->bbr_cycle_current_offset >= 1)
        ++bbr->bbr_cycle_current_offset;

    bbr->bbr_last_cycle_start = now;
    bbr->bbr_pacing_gain = kPacingGain[bbr->bbr_cycle_current_offset];
}



static void enter_startup_mode (struct lsquic_bbr *bbr, lsquic_time_t now)
{
    set_mode(bbr, BBR_MODE_STARTUP);
    set_startup_values(bbr);
}



static void maybe_exit_startup_or_drain (struct lsquic_bbr *bbr, lsquic_time_t now, uint64_t bytes_in_flight)

{
    uint64_t target_cwnd;

    if (bbr->bbr_mode == BBR_MODE_STARTUP && (bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH))
    {
        on_exit_startup(bbr, now);
        set_mode(bbr, BBR_MODE_DRAIN);
        bbr->bbr_pacing_gain = bbr->bbr_drain_gain;
        bbr->bbr_cwnd_gain = bbr->bbr_high_cwnd_gain;
    }

    if (bbr->bbr_mode == BBR_MODE_DRAIN)
    {
        target_cwnd = get_target_cwnd(bbr, 1);
        LSQ_DEBUG("%s: bytes in flight: %"PRIu64"; target cwnd: %"PRIu64, __func__, bytes_in_flight, target_cwnd);
        if (bytes_in_flight <= target_cwnd)
            enter_probe_bw_mode(bbr, now);
    }
}


static int in_slow_start (const struct lsquic_bbr *bbr)
{
    return bbr->bbr_mode == BBR_MODE_STARTUP;
}



static uint64_t get_probe_rtt_cwnd (const struct lsquic_bbr *bbr)
{
    if (bbr->bbr_flags & BBR_FLAG_PROBE_RTT_BASED_ON_BDP)
        return get_target_cwnd(bbr, kModerateProbeRttMultiplier);
    else return bbr->bbr_min_cwnd;
}


static uint64_t lsquic_bbr_get_cwnd (void *cong_ctl)
{
    struct lsquic_bbr *const bbr = cong_ctl;
    uint64_t cwnd;

    if (bbr->bbr_mode == BBR_MODE_PROBE_RTT)
        cwnd = get_probe_rtt_cwnd(bbr);
    else if (in_recovery(bbr) && !((bbr->bbr_flags & BBR_FLAG_RATE_BASED_STARTUP)
                                    && bbr->bbr_mode == BBR_MODE_STARTUP))
        cwnd = MIN(bbr->bbr_cwnd, bbr->bbr_recovery_window);
    else cwnd = bbr->bbr_cwnd;

    return cwnd;
}



static void maybe_enter_or_exit_probe_rtt (struct lsquic_bbr *bbr, lsquic_time_t now, int is_round_start, int min_rtt_expired, uint64_t bytes_in_flight)

{
    if (min_rtt_expired && !(bbr->bbr_flags & BBR_FLAG_EXITING_QUIESCENCE)
                && bbr->bbr_mode != BBR_MODE_PROBE_RTT)
    {
        if (in_slow_start(bbr))
            on_exit_startup(bbr, now);
        set_mode(bbr, BBR_MODE_PROBE_RTT);
        bbr->bbr_pacing_gain = 1;
        
        
        bbr->bbr_exit_probe_rtt_at = 0;
    }

    if (bbr->bbr_mode == BBR_MODE_PROBE_RTT)
    {
        lsquic_bw_sampler_app_limited(&bbr->bbr_bw_sampler);
        LSQ_DEBUG("%s: exit probe at: %"PRIu64"; now: %"PRIu64 "; round start: %d; round passed: %d; rtt: %"PRIu64" usec", __func__, bbr->bbr_exit_probe_rtt_at, now, is_round_start, !!(bbr->bbr_flags & BBR_FLAG_PROBE_RTT_ROUND_PASSED), lsquic_rtt_stats_get_min_rtt(bbr->bbr_rtt_stats));



        if (bbr->bbr_exit_probe_rtt_at == 0)
        {
            
            
            
            
            if (bytes_in_flight < get_probe_rtt_cwnd(bbr) + kMaxOutgoingPacketSize)
            {
                bbr->bbr_exit_probe_rtt_at = now + kProbeRttTime;
                bbr->bbr_flags &= ~BBR_FLAG_PROBE_RTT_ROUND_PASSED;
            }
        }
        else {
            if (is_round_start)
                bbr->bbr_flags |= BBR_FLAG_PROBE_RTT_ROUND_PASSED;
            if (now >= bbr->bbr_exit_probe_rtt_at && (bbr->bbr_flags & BBR_FLAG_PROBE_RTT_ROUND_PASSED))
            {
                bbr->bbr_min_rtt_timestamp = now;
                if (!(bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH))
                    enter_startup_mode(bbr, now);
                else enter_probe_bw_mode(bbr, now);
            }
        }
    }

    bbr->bbr_flags &= ~BBR_FLAG_EXITING_QUIESCENCE;
}



static void calculate_pacing_rate (struct lsquic_bbr *bbr)
{
    struct bandwidth bw, target_rate;

    bw = BW(minmax_get(&bbr->bbr_max_bandwidth));
    if (BW_IS_ZERO(&bw))
        return;

    LSQ_DEBUG("BW estimate: %"PRIu64, BW_VALUE(&bw));

    target_rate = BW_TIMES(&bw, bbr->bbr_pacing_gain);
    if (bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH)
    {
        bbr->bbr_pacing_rate = target_rate;
        return;
    }

    
    
    if (BW_IS_ZERO(&bbr->bbr_pacing_rate)
            && 0 != lsquic_rtt_stats_get_min_rtt(bbr->bbr_rtt_stats))
    {
        bbr->bbr_pacing_rate = BW_FROM_BYTES_AND_DELTA( bbr->bbr_init_cwnd, lsquic_rtt_stats_get_min_rtt(bbr->bbr_rtt_stats));

        return;
    }

    
    const int has_ever_detected_loss = bbr->bbr_end_recovery_at != 0;
    if (has_ever_detected_loss && (bbr->bbr_flags & (BBR_FLAG_SLOWER_STARTUP |BBR_FLAG_HAS_NON_APP_LIMITED))

                == (BBR_FLAG_SLOWER_STARTUP|BBR_FLAG_HAS_NON_APP_LIMITED))
    {
        bbr->bbr_pacing_rate = BW_TIMES(&bw, kStartupAfterLossGain);
        return;
    }

    
    if (startup_rate_reduction_multiplier_ != 0 && has_ever_detected_loss && (bbr->bbr_flags & BBR_FLAG_HAS_NON_APP_LIMITED))

    {
        bbr->bbr_pacing_rate = BW_TIMES(&target_rate, (1 - (bbr->bbr_startup_bytes_lost * startup_rate_reduction_multiplier_ * 1.0f / bbr->bbr_cwnd_gain)));


        
        
        if (BW_VALUE(&bbr->bbr_pacing_rate)
                                        < BW_VALUE(&bw) * kStartupGrowthTarget)
            bbr->bbr_pacing_rate = BW_TIMES(&bw, kStartupGrowthTarget);
        return;
    }

    
    if (BW_VALUE(&bbr->bbr_pacing_rate) < BW_VALUE(&target_rate))
        bbr->bbr_pacing_rate = target_rate;
}



static void calculate_cwnd (struct lsquic_bbr *bbr, uint64_t bytes_acked, uint64_t excess_acked)

{
    if (bbr->bbr_mode == BBR_MODE_PROBE_RTT)
        return;

    uint64_t target_window = get_target_cwnd(bbr, bbr->bbr_cwnd_gain);
    if (bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH)
        
        target_window += minmax_get(&bbr->bbr_max_ack_height);
    else if (bbr->bbr_flags & BBR_FLAG_ENABLE_ACK_AGG_IN_STARTUP)
        
        
        target_window += excess_acked;

    
    
    
    const int add_bytes_acked = !FLAGS_quic_bbr_no_bytes_acked_in_startup_recovery || !in_recovery(bbr);
    if (bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH)
        bbr->bbr_cwnd = MIN(target_window, bbr->bbr_cwnd + bytes_acked);
    else if (add_bytes_acked && (bbr->bbr_cwnd < target_window || lsquic_bw_sampler_total_acked(&bbr->bbr_bw_sampler)

                                                        < bbr->bbr_init_cwnd))
        
        
        bbr->bbr_cwnd += bytes_acked;

    
    if (bbr->bbr_cwnd < bbr->bbr_min_cwnd)
        bbr->bbr_cwnd = bbr->bbr_min_cwnd;
    else if (bbr->bbr_cwnd > bbr->bbr_max_cwnd)
    {
        LSQ_DEBUG("exceed max cwnd");
        bbr->bbr_cwnd = bbr->bbr_max_cwnd;
    }
}



static void calculate_recovery_window (struct lsquic_bbr *bbr, uint64_t bytes_acked, uint64_t bytes_lost, uint64_t bytes_in_flight)

{
    if ((bbr->bbr_flags & BBR_FLAG_RATE_BASED_STARTUP)
                                        && bbr->bbr_mode == BBR_MODE_STARTUP)
        return;

    if (bbr->bbr_recovery_state == BBR_RS_NOT_IN_RECOVERY)
        return;

    
    if (bbr->bbr_recovery_window == 0)
    {
        bbr->bbr_recovery_window = bytes_in_flight + bytes_acked;
        bbr->bbr_recovery_window = MAX(bbr->bbr_min_cwnd, bbr->bbr_recovery_window);
        return;
    }

    
    
    if (bbr->bbr_recovery_window >= bytes_lost)
        bbr->bbr_recovery_window -= bytes_lost;
    else bbr->bbr_recovery_window = kMaxSegmentSize;

    
    
    if (bbr->bbr_recovery_state == BBR_RS_GROWTH)
        bbr->bbr_recovery_window += bytes_acked;

    
    
    bbr->bbr_recovery_window = MAX(bbr->bbr_recovery_window, bytes_in_flight + bytes_acked);
    if (FLAG_quic_bbr_one_mss_conservation)
        bbr->bbr_recovery_window = MAX(bbr->bbr_recovery_window, bytes_in_flight + kMaxSegmentSize);
    bbr->bbr_recovery_window = MAX(bbr->bbr_recovery_window, bbr->bbr_min_cwnd);
}


static void lsquic_bbr_end_ack (void *cong_ctl, uint64_t in_flight)
{
    struct lsquic_bbr *const bbr = cong_ctl;
    int is_round_start, min_rtt_expired;
    uint64_t bytes_acked, excess_acked, bytes_lost;

    assert(bbr->bbr_flags & BBR_FLAG_IN_ACK);
    bbr->bbr_flags &= ~BBR_FLAG_IN_ACK;

    LSQ_DEBUG("end_ack; mode: %s; in_flight: %"PRIu64, mode2str[bbr->bbr_mode], in_flight);

    bytes_acked = lsquic_bw_sampler_total_acked(&bbr->bbr_bw_sampler)
                            - bbr->bbr_ack_state.total_bytes_acked_before;
    if (bbr->bbr_ack_state.acked_bytes)
    {
        is_round_start = bbr->bbr_ack_state.max_packno > bbr->bbr_current_round_trip_end || !is_valid_packno(bbr->bbr_current_round_trip_end);

        if (is_round_start)
        {
            ++bbr->bbr_round_count;
            bbr->bbr_current_round_trip_end = bbr->bbr_last_sent_packno;
            LSQ_DEBUG("up round count to %"PRIu64"; new rt end: %"PRIu64, bbr->bbr_round_count, bbr->bbr_current_round_trip_end);
        }
        min_rtt_expired = update_bandwidth_and_min_rtt(bbr);
        update_recovery_state(bbr, is_round_start);
        excess_acked = update_ack_aggregation_bytes(bbr, bytes_acked);
    }
    else {
        is_round_start = 0;
        min_rtt_expired = 0;
        excess_acked = 0;
    }

    if (bbr->bbr_mode == BBR_MODE_PROBE_BW)
        update_gain_cycle_phase(bbr, in_flight);

    if (is_round_start && !(bbr->bbr_flags & BBR_FLAG_IS_AT_FULL_BANDWIDTH))
        check_if_full_bw_reached(bbr);

    maybe_exit_startup_or_drain(bbr, bbr->bbr_ack_state.ack_time, in_flight);

    maybe_enter_or_exit_probe_rtt(bbr, bbr->bbr_ack_state.ack_time, is_round_start, min_rtt_expired, in_flight);

    
    bytes_lost = bbr->bbr_ack_state.lost_bytes;

    
    
    calculate_pacing_rate(bbr);
    calculate_cwnd(bbr, bytes_acked, excess_acked);
    calculate_recovery_window(bbr, bytes_acked, bytes_lost, in_flight);

    
}


static void lsquic_bbr_cleanup (void *cong_ctl)
{
    struct lsquic_bbr *const bbr = cong_ctl;

    lsquic_bw_sampler_cleanup(&bbr->bbr_bw_sampler);
    LSQ_DEBUG("cleanup");
}


static void lsquic_bbr_loss (void *cong_ctl) {      }


static void lsquic_bbr_timeout (void *cong_ctl) {      }


const struct cong_ctl_if lsquic_cong_bbr_if = {
    .cci_ack           = lsquic_bbr_ack, .cci_begin_ack     = lsquic_bbr_begin_ack, .cci_end_ack       = lsquic_bbr_end_ack, .cci_cleanup       = lsquic_bbr_cleanup, .cci_get_cwnd      = lsquic_bbr_get_cwnd, .cci_init          = lsquic_bbr_init, .cci_pacing_rate   = lsquic_bbr_pacing_rate, .cci_loss          = lsquic_bbr_loss, .cci_lost          = lsquic_bbr_lost, .cci_reinit        = lsquic_bbr_reinit, .cci_timeout       = lsquic_bbr_timeout, .cci_sent          = lsquic_bbr_sent, .cci_was_quiet     = lsquic_bbr_was_quiet, };












