















namespace tensorflow {


TF_PLATFORM_STRINGS()

typedef Eigen::ThreadPoolDevice CPUDevice;

namespace {


constexpr int kMinBlockSize = 512;



int NumBinaryDigits(int n) {
  return static_cast<int>(std::log2(n) + 1);
}



int RightmostZeroBit(int n) {
  int k = 0;
  while (n & 1) {
    n >>= 1;
    ++k;
  }
  return k;
}



Eigen::VectorXi GetFirstPoint(int i, int dim, const Eigen::MatrixXi& direction_numbers) {
  
  
  
  
  Eigen::VectorXi integer_sequence = Eigen::VectorXi::Zero(dim);
  
  int gray_code = i ^ (i >> 1);
  int num_digits = NumBinaryDigits(i);
  for (int j = 0; j < dim; ++j) {
    for (int k = 0; k < num_digits; ++k) {
      if ((gray_code >> k) & 1) integer_sequence(j) ^= direction_numbers(j, k);
    }
  }
  return integer_sequence;
}




template <typename T> void CalculateSobolSample(int32_t dim, int32_t num_results, int32_t skip, int32_t start_point, typename TTypes<T>::Flat output) {


  
  
  
  
  const int num_digits = NumBinaryDigits(skip + start_point + num_results + 1);
  Eigen::MatrixXi direction_numbers(dim, num_digits);

  
  
  const T normalizing_constant = 1./(1 << num_digits);
  for (int j = 0; j < dim; ++j) {
    for (int k = 0; k < num_digits; ++k) {
      direction_numbers(j, k) = sobol_data::kDirectionNumbers[j][k] << (num_digits - k - 1);
    }
  }

  
  
  Eigen::VectorXi integer_sequence = (skip + start_point > 0)
          ? GetFirstPoint(skip + start_point + 1, dim, direction_numbers)
          : direction_numbers.col(0);

  for (int j = 0; j < dim; ++j) {
    output(start_point * dim + j) = integer_sequence(j) * normalizing_constant;
  }
  
  for (int i = start_point + 1; i < num_results + start_point; ++i) {
    
    
    int k = RightmostZeroBit(i + skip);
    
    
    for (int j = 0; j < dim; ++j) {
      integer_sequence(j) ^= direction_numbers(j, k);
      output(i * dim + j) = integer_sequence(j) * normalizing_constant;
    }
  }
}

}  

template <typename Device, typename T> class SobolSampleOp : public OpKernel {
 public:
  explicit SobolSampleOp(OpKernelConstruction* context)
      : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    int32_t dim = context->input(0).scalar<int32_t>()();
    int32_t num_results = context->input(1).scalar<int32_t>()();
    int32_t skip = context->input(2).scalar<int32_t>()();

    OP_REQUIRES(context, dim >= 1, errors::InvalidArgument("dim must be at least one"));
    OP_REQUIRES(context, dim <= sobol_data::kMaxSobolDim, errors::InvalidArgument("dim must be at most ", sobol_data::kMaxSobolDim));

    OP_REQUIRES(context, num_results >= 1, errors::InvalidArgument("num_results must be at least one"));
    OP_REQUIRES(context, skip >= 0, errors::InvalidArgument("skip must be non-negative"));
    OP_REQUIRES(context, num_results < std::numeric_limits<int32_t>::max() - skip, errors::InvalidArgument("num_results+skip must be less than ", std::numeric_limits<int32_t>::max()));



    Tensor* output = nullptr;
    OP_REQUIRES_OK(context, context->allocate_output( 0, TensorShape({num_results, dim}), &output));

    auto output_flat = output->flat<T>();
    const DeviceBase::CpuWorkerThreads& worker_threads = *(context->device()->tensorflow_cpu_worker_threads());
    int num_threads = worker_threads.num_threads;
    int block_size = std::max( kMinBlockSize, static_cast<int>(std::ceil( static_cast<float>(num_results) / num_threads)));

    worker_threads.workers->TransformRangeConcurrently( block_size, num_results , [&dim, &skip, &output_flat](const int start, const int end) {

          CalculateSobolSample<T>(dim, end - start , skip, start, output_flat);
        });
  }
};

REGISTER_KERNEL_BUILDER( Name("SobolSample").Device(DEVICE_CPU).TypeConstraint<double>("dtype"), SobolSampleOp<CPUDevice, double>);

REGISTER_KERNEL_BUILDER( Name("SobolSample").Device(DEVICE_CPU).TypeConstraint<float>("dtype"), SobolSampleOp<CPUDevice, float>);


}  
