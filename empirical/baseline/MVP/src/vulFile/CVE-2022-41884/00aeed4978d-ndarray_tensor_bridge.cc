












namespace tensorflow {



static mutex* DelayedDecrefLock() {
  static mutex* decref_lock = new mutex;
  return decref_lock;
}


static std::vector<void*>* DecrefCache() {
  static std::vector<void*>* decref_cache = new std::vector<void*>;
  return decref_cache;
}




void DelayedNumpyDecref(void* data, size_t len, void* obj) {
  mutex_lock ml(*DelayedDecrefLock());
  DecrefCache()->push_back(obj);
}



void ClearDecrefCache() {
  std::vector<void*> cache_copy;
  {
    mutex_lock ml(*DelayedDecrefLock());
    cache_copy.swap(*DecrefCache());
  }
  for (void* obj : cache_copy) {
    Py_DECREF(reinterpret_cast<PyObject*>(obj));
  }
}



struct TensorReleaser {
  
  PyObject_HEAD   std::function<void()>* destructor;


};

extern PyTypeObject TensorReleaserType;

static void TensorReleaser_dealloc(PyObject* pself) {
  TensorReleaser* self = reinterpret_cast<TensorReleaser*>(pself);
  (*self->destructor)();
  delete self->destructor;
  TensorReleaserType.tp_free(pself);
}


PyTypeObject TensorReleaserType = {
    PyVarObject_HEAD_INIT(nullptr, 0) 
    "tensorflow_wrapper",              sizeof(TensorReleaser), 0,  TensorReleaser_dealloc,  nullptr,  0,  nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, Py_TPFLAGS_DEFAULT, "Wrapped TensorFlow Tensor", nullptr, nullptr, nullptr, };





























Status TF_DataType_to_PyArray_TYPE(TF_DataType tf_datatype, int* out_pyarray_type) {
  switch (tf_datatype) {
    case TF_HALF:
      *out_pyarray_type = NPY_FLOAT16;
      break;
    case TF_FLOAT:
      *out_pyarray_type = NPY_FLOAT32;
      break;
    case TF_DOUBLE:
      *out_pyarray_type = NPY_FLOAT64;
      break;
    case TF_INT32:
      *out_pyarray_type = NPY_INT32;
      break;
    case TF_UINT32:
      *out_pyarray_type = NPY_UINT32;
      break;
    case TF_UINT8:
      *out_pyarray_type = NPY_UINT8;
      break;
    case TF_UINT16:
      *out_pyarray_type = NPY_UINT16;
      break;
    case TF_INT8:
      *out_pyarray_type = NPY_INT8;
      break;
    case TF_INT16:
      *out_pyarray_type = NPY_INT16;
      break;
    case TF_INT64:
      *out_pyarray_type = NPY_INT64;
      break;
    case TF_UINT64:
      *out_pyarray_type = NPY_UINT64;
      break;
    case TF_BOOL:
      *out_pyarray_type = NPY_BOOL;
      break;
    case TF_COMPLEX64:
      *out_pyarray_type = NPY_COMPLEX64;
      break;
    case TF_COMPLEX128:
      *out_pyarray_type = NPY_COMPLEX128;
      break;
    case TF_STRING:
      *out_pyarray_type = NPY_OBJECT;
      break;
    case TF_RESOURCE:
      *out_pyarray_type = NPY_VOID;
      break;
    
    
    
    case TF_QINT8:
      *out_pyarray_type = NPY_INT8;
      break;
    case TF_QUINT8:
      *out_pyarray_type = NPY_UINT8;
      break;
    case TF_QINT16:
      *out_pyarray_type = NPY_INT16;
      break;
    case TF_QUINT16:
      *out_pyarray_type = NPY_UINT16;
      break;
    case TF_QINT32:
      *out_pyarray_type = NPY_INT32;
      break;
    case TF_BFLOAT16:
      *out_pyarray_type = Bfloat16NumpyType();
      break;
    default:
      return errors::Internal("Tensorflow type ", tf_datatype, " not convertible to numpy dtype.");
  }
  return OkStatus();
}

Status ArrayFromMemory(int dim_size, npy_intp* dims, void* data, DataType dtype, std::function<void()> destructor, PyObject** result) {
  if (dtype == DT_STRING || dtype == DT_RESOURCE) {
    return errors::FailedPrecondition( "Cannot convert string or resource Tensors.");
  }

  int type_num = -1;
  Status s = TF_DataType_to_PyArray_TYPE(static_cast<TF_DataType>(dtype), &type_num);
  if (!s.ok()) {
    return s;
  }

  if (dim_size > NPY_MAXDIMS) {
    return errors::InvalidArgument( "Cannot convert tensor with ", dim_size, " dimensions to NumPy array. NumPy arrays can have at most ", NPY_MAXDIMS, " dimensions");


  }
  auto* np_array = reinterpret_cast<PyArrayObject*>( PyArray_SimpleNewFromData(dim_size, dims, type_num, data));
  PyArray_CLEARFLAGS(np_array, NPY_ARRAY_OWNDATA);
  if (PyType_Ready(&TensorReleaserType) == -1) {
    return errors::Unknown("Python type initialization failed.");
  }
  auto* releaser = reinterpret_cast<TensorReleaser*>( TensorReleaserType.tp_alloc(&TensorReleaserType, 0));
  releaser->destructor = new std::function<void()>(std::move(destructor));
  if (PyArray_SetBaseObject(np_array, reinterpret_cast<PyObject*>(releaser)) == -1) {
    Py_DECREF(releaser);
    return errors::Unknown("Python array refused to use memory.");
  }
  *result = reinterpret_cast<PyObject*>(np_array);
  return OkStatus();
}

}  
