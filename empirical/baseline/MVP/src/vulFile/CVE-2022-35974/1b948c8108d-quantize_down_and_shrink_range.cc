
















namespace tensorflow {

typedef Eigen::ThreadPoolDevice CPUDevice;

template <class T1, class T2> class QuantizeDownAndShrinkRangeOp : public OpKernel {
 public:
  explicit QuantizeDownAndShrinkRangeOp(OpKernelConstruction* ctx)
      : OpKernel(ctx) {}

  void Compute(OpKernelContext* ctx) override {
    const Tensor& input = ctx->input(0);
    const float input_min_float = ctx->input(1).flat<float>()(0);
    const float input_max_float = ctx->input(2).flat<float>()(0);
    Tensor* output = nullptr;
    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));
    Tensor* output_min = nullptr;
    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));
    Tensor* output_max = nullptr;
    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));

    
    auto input_array = input.flat<T1>();
    const int32_t input_lowest_quantized = static_cast<int32>(Eigen::NumTraits<T1>::lowest());
    const int32_t input_highest_quantized = static_cast<int32>(Eigen::NumTraits<T1>::highest());
    T1 actual_min_quantized = input_highest_quantized;
    T1 actual_max_quantized = input_lowest_quantized;
    for (int i = 0; i < input_array.size(); ++i) {
      const T1 value = input_array(i);
      actual_min_quantized = std::min(actual_min_quantized, value);
      actual_max_quantized = std::max(actual_max_quantized, value);
    }
    
    
    const float actual_min_float = std::min(0.0f, QuantizedToFloat(actual_min_quantized, input_min_float, input_max_float));

    const float actual_max_float = QuantizedToFloat( actual_max_quantized, input_min_float, input_max_float);


    
    auto output_array = output->flat<T2>();
    RequantizeManyInNewRange<T1, T2>(input_array.data(), input_array.size(), input_min_float, input_max_float, actual_min_float, actual_max_float, output_array.data());




    if (input_array.size() > 0) {
      if (meta::IsSupportedAndEnabled() && std::is_same<T1, qint32>() && std::is_same<T2, quint8>()) {
        auto input_i32_array = input.flat<qint32>();
        meta::Requantize(ctx, input_i32_array.data(), input_i32_array.size(), input_min_float, input_max_float, actual_min_float, actual_max_float, output->flat<quint8>().data());

      } else {
        RequantizeManyInNewRangeUsingEigen<T1, T2>( ctx->eigen_device<CPUDevice>(), input, input_min_float, input_max_float, actual_min_float, actual_max_float, output);

      }
    }

    output_min->flat<float>().setConstant(actual_min_float);
    output_max->flat<float>().setConstant(actual_max_float);
  }
};

REGISTER_KERNEL_BUILDER(Name("QuantizeDownAndShrinkRange")
                            .Device(DEVICE_CPU)
                            .TypeConstraint<qint32>("Tinput")
                            .TypeConstraint<quint8>("out_type"), QuantizeDownAndShrinkRangeOp<qint32, quint8>);

}  
