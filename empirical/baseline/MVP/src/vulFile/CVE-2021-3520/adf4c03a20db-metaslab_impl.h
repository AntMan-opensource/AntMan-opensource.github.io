
















extern "C" {



typedef struct metaslab_alloc_trace {
	list_node_t			mat_list_node;
	metaslab_group_t		*mat_mg;
	metaslab_t			*mat_msp;
	uint64_t			mat_size;
	uint64_t			mat_weight;
	uint32_t			mat_dva_id;
	uint64_t			mat_offset;
	int					mat_allocator;
} metaslab_alloc_trace_t;


typedef enum trace_alloc_type {
	TRACE_ALLOC_FAILURE	= -1ULL, TRACE_TOO_SMALL		= -2ULL, TRACE_FORCE_GANG	= -3ULL, TRACE_NOT_ALLOCATABLE	= -4ULL, TRACE_GROUP_FAILURE	= -5ULL, TRACE_ENOSPC		= -6ULL, TRACE_CONDENSING	= -7ULL, TRACE_VDEV_ERROR	= -8ULL, TRACE_DISABLED		= -9ULL, } trace_alloc_type_t;






























typedef struct metaslab_class_allocator {
	metaslab_group_t	*mca_rotor;
	uint64_t		mca_aliquot;

	
	uint64_t		mca_alloc_max_slots;
	zfs_refcount_t		mca_alloc_slots;
} ____cacheline_aligned metaslab_class_allocator_t;


struct metaslab_class {
	kmutex_t		mc_lock;
	spa_t			*mc_spa;
	metaslab_ops_t		*mc_ops;

	
	uint64_t		mc_groups;

	
	boolean_t		mc_alloc_throttle_enabled;

	uint64_t		mc_alloc_groups; 

	uint64_t		mc_alloc;	
	uint64_t		mc_deferred;	
	uint64_t		mc_space;	
	uint64_t		mc_dspace;	
	uint64_t		mc_histogram[RANGE_TREE_HISTOGRAM_SIZE];

	
	multilist_t		mc_metaslab_txg_list;

	metaslab_class_allocator_t	mc_allocator[];
};


typedef struct metaslab_group_allocator {
	uint64_t	mga_cur_max_alloc_queue_depth;
	zfs_refcount_t	mga_alloc_queue_depth;
	metaslab_t	*mga_primary;
	metaslab_t	*mga_secondary;
} metaslab_group_allocator_t;


struct metaslab_group {
	kmutex_t		mg_lock;
	avl_tree_t		mg_metaslab_tree;
	uint64_t		mg_aliquot;
	boolean_t		mg_allocatable;		
	uint64_t		mg_ms_ready;

	
	boolean_t		mg_initialized;

	uint64_t		mg_free_capacity;	
	int64_t			mg_bias;
	int64_t			mg_activation_count;
	metaslab_class_t	*mg_class;
	vdev_t			*mg_vd;
	taskq_t			*mg_taskq;
	metaslab_group_t	*mg_prev;
	metaslab_group_t	*mg_next;

	
	uint64_t		mg_max_alloc_queue_depth;

	
	boolean_t		mg_no_free_space;

	uint64_t		mg_allocations;
	uint64_t		mg_failed_allocations;
	uint64_t		mg_fragmentation;
	uint64_t		mg_histogram[RANGE_TREE_HISTOGRAM_SIZE];

	int			mg_ms_disabled;
	boolean_t		mg_disabled_updating;
	kmutex_t		mg_ms_disabled_lock;
	kcondvar_t		mg_ms_disabled_cv;

	int			mg_allocators;
	metaslab_group_allocator_t	mg_allocator[];
};





struct metaslab {
	
	kmutex_t	ms_lock;

	
	kmutex_t	ms_sync_lock;

	kcondvar_t	ms_load_cv;
	space_map_t	*ms_sm;
	uint64_t	ms_id;
	uint64_t	ms_start;
	uint64_t	ms_size;
	uint64_t	ms_fragmentation;

	range_tree_t	*ms_allocating[TXG_SIZE];
	range_tree_t	*ms_allocatable;
	uint64_t	ms_allocated_this_txg;
	uint64_t	ms_allocating_total;

	
	range_tree_t	*ms_freeing;	
	range_tree_t	*ms_freed;	
	range_tree_t	*ms_defer[TXG_DEFER_SIZE];
	range_tree_t	*ms_checkpointing; 

	
	range_tree_t	*ms_trim;

	boolean_t	ms_condensing;	
	boolean_t	ms_condense_wanted;

	
	uint64_t	ms_disabled;

	
	boolean_t	ms_loaded;
	boolean_t	ms_loading;
	kcondvar_t	ms_flush_cv;
	boolean_t	ms_flushing;

	
	uint64_t	ms_synchist[SPACE_MAP_HISTOGRAM_SIZE];
	uint64_t	ms_deferhist[TXG_DEFER_SIZE][SPACE_MAP_HISTOGRAM_SIZE];

	
	uint64_t	ms_allocated_space;
	int64_t		ms_deferspace;	
	uint64_t	ms_weight;	
	uint64_t	ms_activation_weight;	

	
	uint64_t	ms_selected_txg;
	
	hrtime_t	ms_load_time;	
	hrtime_t	ms_unload_time;	
	hrtime_t	ms_selected_time; 

	uint64_t	ms_alloc_txg;	
	uint64_t	ms_max_size;	

	
	int		ms_allocator;
	boolean_t	ms_primary; 

	
	zfs_btree_t		ms_allocatable_by_size;
	zfs_btree_t		ms_unflushed_frees_by_size;
	uint64_t	ms_lbas[MAX_LBAS];

	metaslab_group_t *ms_group;	
	avl_node_t	ms_group_node;	
	txg_node_t	ms_txg_node;	
	avl_node_t	ms_spa_txg_node; 
	
	multilist_node_t	ms_class_txg_node;

	
	range_tree_t	*ms_unflushed_allocs;
	range_tree_t	*ms_unflushed_frees;

	
	uint64_t	ms_unflushed_txg;

	
	uint64_t	ms_synced_length;

	boolean_t	ms_new;
};

typedef struct metaslab_unflushed_phys {
	
	uint64_t	msp_unflushed_txg;
} metaslab_unflushed_phys_t;


}



