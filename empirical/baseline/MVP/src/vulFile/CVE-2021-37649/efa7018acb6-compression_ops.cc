






namespace tensorflow {
namespace data {
namespace experimental {

CompressElementOp::CompressElementOp(OpKernelConstruction* ctx)
    : OpKernel(ctx) {}

void CompressElementOp::Compute(OpKernelContext* ctx) {
  std::vector<Tensor> components;
  for (size_t i = 0; i < ctx->num_inputs(); ++i) {
    components.push_back(ctx->input(i));
  }
  CompressedElement compressed;
  OP_REQUIRES_OK(ctx, CompressElement(components, &compressed));

  Tensor* output;
  OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &output));
  output->scalar<Variant>()() = std::move(compressed);
}

UncompressElementOp::UncompressElementOp(OpKernelConstruction* ctx)
    : OpKernel(ctx) {
  OP_REQUIRES_OK(ctx, ctx->GetAttr(kOutputTypes, &output_types_));
  OP_REQUIRES_OK(ctx, ctx->GetAttr(kOutputShapes, &output_shapes_));
}

void UncompressElementOp::Compute(OpKernelContext* ctx) {
  Tensor tensor = ctx->input(0);
  const Variant& variant = tensor.scalar<Variant>()();
  const CompressedElement* compressed = variant.get<CompressedElement>();

  std::vector<Tensor> components;
  OP_REQUIRES_OK(ctx, UncompressElement(*compressed, &components));
  OP_REQUIRES(ctx, components.size() == output_types_.size(), errors::FailedPrecondition("Expected ", output_types_.size(), " outputs from uncompress, but got ", components.size()));


  for (int i = 0; i < components.size(); ++i) {
    OP_REQUIRES( ctx, components[i].dtype() == output_types_[i], errors::FailedPrecondition("Expected a tensor of type ", DataTypeString(output_types_[i]), " but got a tensor of type ", DataTypeString(components[i].dtype())));




    ctx->set_output(i, components[i]);
  }
}

REGISTER_KERNEL_BUILDER(Name("CompressElement").Device(DEVICE_CPU), CompressElementOp);
REGISTER_KERNEL_BUILDER(Name("UncompressElement").Device(DEVICE_CPU), UncompressElementOp);

}  
}  
}  
