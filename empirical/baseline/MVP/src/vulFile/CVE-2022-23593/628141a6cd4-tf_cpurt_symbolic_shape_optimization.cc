


























namespace tensorflow {
namespace {

using llvm::ArrayRef;
using llvm::SmallVector;

using mlir::AffineExpr;
using mlir::AffineMap;
using mlir::failure;
using mlir::FuncOp;
using mlir::FunctionPass;
using mlir::Location;
using mlir::LogicalResult;
using mlir::MLIRContext;
using mlir::OpBuilder;
using mlir::RankedTensorType;
using mlir::ShapeComponentAnalysis;
using mlir::success;
using mlir::TypeRange;
using mlir::Value;
using mlir::ValueRange;
using mlir::arith::ConstantIndexOp;
using mlir::arith::ConstantOp;
using mlir::arith::IndexCastOp;

namespace linalg = mlir::linalg;
namespace mhlo = mlir::mhlo;
namespace shape = mlir::shape;
namespace tensor = mlir::tensor;









class CstrBroadcastableOpLowering : public mlir::OpRewritePattern<shape::CstrBroadcastableOp> {
 public:
  using Base = OpRewritePattern<shape::CstrBroadcastableOp>;

  explicit CstrBroadcastableOpLowering(MLIRContext* ctx);

  LogicalResult matchAndRewrite(shape::CstrBroadcastableOp op, mlir::PatternRewriter& rewriter) const override;
};

CstrBroadcastableOpLowering::CstrBroadcastableOpLowering(MLIRContext* ctx)
    : Base(ctx) {}


bool isKnownBroadcastable(ShapeComponentAnalysis& analysis, ValueRange bcasted_shapes, Value output_shape) {
  auto output_shape_dims = analysis.GetValueInfo(output_shape);
  if (!output_shape_dims) return false;
  for (Value shape : bcasted_shapes) {
    auto shape_dims = analysis.GetValueInfo(shape);
    if (!shape_dims) return false;
    
    for (auto zip : llvm::zip(llvm::reverse(*output_shape_dims), llvm::reverse(*shape_dims))) {
      const auto& first = std::get<0>(zip);
      const auto& second = std::get<1>(zip);
      
      
      
      
      
      
      if (first.isConstant(0) || second.isConstant(0)) return false;
      
      
      if (first.isConstant(1) || second.isConstant(1)) continue;
      
      if (first != second) return false;
    }
  }
  return true;
}

LogicalResult CstrBroadcastableOpLowering::matchAndRewrite( shape::CstrBroadcastableOp op, mlir::PatternRewriter& rewriter) const {
  ShapeComponentAnalysis shape_component_analysis;
  if (!isKnownBroadcastable(shape_component_analysis, op.getShapes(), op.getShapes().front()))
    return failure();

  
  rewriter.replaceOpWithNewOp<shape::ConstWitnessOp>(op, true);

  return success();
}


class BroadcastOpLowering final : public mlir::OpRewritePattern<shape::BroadcastOp> {
 public:
  explicit BroadcastOpLowering(MLIRContext* ctx) : OpRewritePattern(ctx) {}

  LogicalResult matchAndRewrite(shape::BroadcastOp op, mlir::PatternRewriter& rewriter) const override;
};



llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis, ValueRange shapes, Location loc, OpBuilder* builder) {

  
  SmallVector<ArrayRef<ShapeComponentAnalysis::SymbolicExpr>> shapes_found;
  size_t maxRank = 0;
  for (const auto &shape : llvm::enumerate(shapes)) {
    auto found_shape = analysis.GetValueInfo(shape.value());
    if (!found_shape) return {};
    shapes_found.push_back(*found_shape);
    maxRank = std::max(maxRank, found_shape->size());
  }

  SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions( maxRank);
  SmallVector<std::pair<Value, int64_t>> shape_and_rank_for_dim(maxRank);
  for (const auto &shape : llvm::enumerate(shapes_found)) {
    for (const auto &dim : llvm::enumerate(llvm::reverse(shape.value()))) {
      
      if (dim.value().isConstant(1)) continue;
      
      
      auto index = maxRank - dim.index() - 1;
      if (!joined_dimensions[index]) {
        joined_dimensions[index] = &dim.value();
        shape_and_rank_for_dim[index] = std::make_pair(shapes[shape.index()], shape.value().size());
        continue;
      }
      
      if (*joined_dimensions[index] != dim.value()) return {};
    }
  }
  
  if (llvm::is_splat(shape_and_rank_for_dim) && shape_and_rank_for_dim[0].first) {
    return shape_and_rank_for_dim[0].first;
  }
  
  SmallVector<Value> elements;
  for (int i = 0; i != maxRank; ++i) {
    
    if (!shape_and_rank_for_dim[i].first) {
      auto one = builder->getIntegerAttr( shapes[0].getType().cast<RankedTensorType>().getElementType(), 1);
      elements.push_back(builder->create<ConstantOp>(loc, one));
      continue;
    }
    
    
    Value index = builder->create<ConstantIndexOp>( loc, i - maxRank + shape_and_rank_for_dim[i].second);
    elements.push_back(builder->create<tensor::ExtractOp>( loc, shape_and_rank_for_dim[i].first, index));
  }
  return Value(builder->create<tensor::FromElementsOp>(loc, elements));
}

LogicalResult BroadcastOpLowering::matchAndRewrite( shape::BroadcastOp op, mlir::PatternRewriter& rewriter) const {
  ShapeComponentAnalysis shape_component_analysis;
  auto new_broadcast = simplifyBroadcast( shape_component_analysis, op.getShapes(), op.getLoc(), &rewriter);
  if (!new_broadcast) return failure();
  rewriter.replaceOp(op, {*new_broadcast});
  return success();
}





class DynamicBroadcastInDimOpLowering : public mlir::OpRewritePattern<mhlo::DynamicBroadcastInDimOp> {
 public:
  using Base = OpRewritePattern<mhlo::DynamicBroadcastInDimOp>;

  explicit DynamicBroadcastInDimOpLowering(MLIRContext* ctx);

  LogicalResult matchAndRewrite(mhlo::DynamicBroadcastInDimOp op, mlir::PatternRewriter& rewriter) const override;
};

DynamicBroadcastInDimOpLowering::DynamicBroadcastInDimOpLowering( MLIRContext* ctx)
    : Base(ctx) {}



llvm::Optional<AffineMap> isNonExpandingBroadcast( ShapeComponentAnalysis& analysis, Value from, Value to_shape) {
  auto in_shape = analysis.GetShapeInfo(from);
  auto out_shape = analysis.GetValueInfo(to_shape);
  if (!in_shape || !out_shape) return {};

  SmallVector<AffineExpr> input_map_exprs;
  size_t rank = out_shape->size();
  MLIRContext* ctx = (*out_shape)[0].expr.getContext();
  size_t d = 0;
  auto affine_zero = getAffineConstantExpr(0, ctx);
  for (auto zip :
       llvm::zip(llvm::reverse(*in_shape), llvm::reverse(*out_shape))) {
    const auto& in = std::get<0>(zip);
    const auto& out = std::get<1>(zip);
    bool extend = in.isConstant(1) && !out.isConstant(1);
    input_map_exprs.push_back(extend ? affine_zero : getAffineDimExpr(rank - d - 1, ctx));
    ++d;

    
    if (!extend && in != out) return {};
  }
  
  input_map_exprs.resize(in_shape->size(), affine_zero);
  std::reverse(input_map_exprs.begin(), input_map_exprs.end());
  return AffineMap::get(rank, 0, input_map_exprs, ctx);
}

LogicalResult DynamicBroadcastInDimOpLowering::matchAndRewrite( mhlo::DynamicBroadcastInDimOp op, mlir::PatternRewriter& rewriter) const {
  MLIRContext* ctx = getContext();

  auto in_type = op.operand().getType().dyn_cast<RankedTensorType>();
  auto out_type = op.getResult().getType().dyn_cast<RankedTensorType>();
  if (!in_type || !out_type) return failure();

  
  
  auto bcast_dims = op.broadcast_dimensions().getValues<int64_t>();
  auto expected_bcast_dims = llvm::seq<int64_t>( out_type.getRank() - in_type.getRank(), out_type.getRank());
  if (!llvm::equal(bcast_dims, expected_bcast_dims)) return failure();

  ShapeComponentAnalysis shape_component_analysis;
  auto input_map = isNonExpandingBroadcast( shape_component_analysis, op.operand(), op.output_dimensions());
  if (!input_map) return failure();

  
  SmallVector<Value> output_dyn_dimensions;
  Location loc = op.getLoc();
  int64_t rank = out_type.getRank();
  for (size_t d = 0; d < rank; ++d) {
    int64_t output_dim = out_type.getShape()[d];

    
    if (output_dim >= 0) continue;

    
    Value output_dyn_dim = rewriter.create<tensor::ExtractOp>( loc, op.output_dimensions(), ValueRange{rewriter.create<ConstantIndexOp>(loc, d)});


    
    if (!output_dyn_dim.getType().isIndex())
      output_dyn_dim = rewriter.create<IndexCastOp>(loc, output_dyn_dim, rewriter.getIndexType());

    output_dyn_dimensions.push_back(output_dyn_dim);
  }

  
  Value init = rewriter.create<linalg::InitTensorOp>(loc, output_dyn_dimensions, out_type.getShape(), out_type.getElementType());


  
  AffineMap output_map = AffineMap::getMultiDimIdentityMap(rank, ctx);

  
  SmallVector<llvm::StringRef> iterator_types(rank, "parallel");

  rewriter.replaceOpWithNewOp<linalg::GenericOp>( op, TypeRange{init.getType()}, ValueRange{op.operand()}, ValueRange{init}, llvm::makeArrayRef({*input_map, output_map}), iterator_types, [&](OpBuilder& nested_builder, Location nested_loc, ValueRange args) {





        nested_builder.create<linalg::YieldOp>(nested_loc, args[0]);
      });

  return success();
}





struct SymbolicShapeOptimizationPass : public SymbolicShapeOptimizationBase<SymbolicShapeOptimizationPass> {
  SymbolicShapeOptimizationPass() = default;

  explicit SymbolicShapeOptimizationPass(bool constraints_only) {
    this->optimize_only_constraints = constraints_only;
  }

  void runOnFunction() override {
    FuncOp func = getFunction();

    MLIRContext* ctx = &getContext();
    mlir::RewritePatternSet patterns(ctx);

    
    patterns.insert<CstrBroadcastableOpLowering>(ctx);
    
    patterns.insert<BroadcastOpLowering>(ctx);

    
    if (!optimize_only_constraints)
      patterns.insert<DynamicBroadcastInDimOpLowering>(ctx);

    
    
    for (auto op : ctx->getRegisteredOperations()) {
      if (llvm::isa<shape::ShapeDialect>(op.getDialect()))
        op.getCanonicalizationPatterns(patterns, ctx);
    }

    (void)mlir::applyPatternsAndFoldGreedily(func, std::move(patterns));
  }
};

}  

std::unique_ptr<FunctionPass> CreateSymbolicShapeOptimizationPass( bool constraints_only) {
  return std::make_unique<SymbolicShapeOptimizationPass>(constraints_only);
}

}  
