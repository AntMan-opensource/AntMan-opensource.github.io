























namespace tensorflow {

namespace checkpoint {

class TensorSliceWriter {
 public:
  
  class Builder {
   public:
    virtual ~Builder() {}
    virtual void Add(StringPiece key, StringPiece value) = 0;
    virtual Status Finish(int64_t* file_size) = 0;
  };
  typedef std::function<Status(const string&, Builder**)> CreateBuilderFunction;

  TensorSliceWriter(const string& filename, CreateBuilderFunction create_builder);
  virtual ~TensorSliceWriter() {}
  
  
  template <typename T> Status Add(const string& name, const TensorShape& shape, const TensorSlice& slice, const T* data);

  Status Finish();

  
  
  template <typename T> static Status SaveData(const T* data, int64_t num_elements, SavedSlice* ss);

  static size_t MaxBytesPerElement(DataType dt);

 private:
  static constexpr size_t kMaxMessageBytes = 1LL << 31;
  
  
  
  
  
  
  
  
  static constexpr size_t kTensorProtoHeaderBytes = 1 << 10;

  const string filename_;
  const CreateBuilderFunction create_builder_;
  const string tmpname_;

  
  std::unordered_map<string, int> name_to_index_;
  
  SavedTensorSlices sts_;
  
  std::map<string, string> data_;
  
  int slices_;
  TF_DISALLOW_COPY_AND_ASSIGN(TensorSliceWriter);
};

template <typename T> Status TensorSliceWriter::Add(const string& name, const TensorShape& shape, const TensorSlice& slice, const T* data) {

  
  if (shape.dims() != slice.dims()) {
    return errors::Internal("Incompatible tensor shape and slice: ", "shape = ", shape.DebugString(), ", slice = ", slice.DebugString());

  }
  DataType dt = DataTypeToEnum<T>::value;
  
  int index = gtl::FindWithDefault(name_to_index_, name, -1);
  if (index >= 0) {
    
    
    const SavedSliceMeta& ssm = sts_.meta().tensor(index);
    CHECK_EQ(name, ssm.name()) << ssm.ShortDebugString();
    TensorShape ssm_shape(ssm.shape());
    if (!shape.IsSameSize(ssm_shape)) {
      return errors::Internal( "Mismatching shapes: existing tensor = ", ssm_shape.DebugString(), ", trying to add name ", name, ", shape = ", shape.DebugString());

    }
    if (dt != ssm.type()) {
      return errors::Internal( "Mismatching types: existing type = ", DataTypeString(ssm.type()), ", trying to add name ", name, ", type = ", DataTypeString(dt));

    }
  } else {
    
    index = sts_.meta().tensor_size();
    name_to_index_.insert(std::make_pair(name, index));
    SavedSliceMeta* ssm = sts_.mutable_meta()->add_tensor();
    ssm->set_name(name);
    shape.AsProto(ssm->mutable_shape());
    ssm->set_type(dt);
  }
  
  SavedSliceMeta* ssm = sts_.mutable_meta()->mutable_tensor(index);
  slice.AsProto(ssm->add_slice());

  
  {
    SavedTensorSlices sts;
    SavedSlice* ss = sts.mutable_data();
    ss->set_name(name);
    slice.AsProto(ss->mutable_slice());
    TensorShape saved_shape(ssm->shape());
    TensorShape sliced_shape;
    TF_RETURN_IF_ERROR(slice.SliceTensorShape(saved_shape, &sliced_shape));
    TF_RETURN_IF_ERROR(SaveData(data, sliced_shape.num_elements(), ss));
    string key = EncodeTensorNameSlice(name, slice);
    
    
    
    std::pair<string, string> key_value(key, "");
    if (!sts.AppendToString(&key_value.second)) {
      return errors::Internal("Error writing Tensor. Possible size overflow.");
    }
    data_.insert(key_value);
  }
  ++slices_;
  return OkStatus();
}

template <typename T> Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements, SavedSlice* ss) {

  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes + (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);

  if (size_bound > kMaxMessageBytes) {
    return errors::InvalidArgument( "Tensor slice is too large to serialize (conservative estimate: ", size_bound, " bytes)");

  }
  Fill(data, num_elements, ss->mutable_data());
  DCHECK_GE(ss->ByteSize(), 0);
  DCHECK_LE(ss->ByteSize(), size_bound);
  return OkStatus();
}

template <> Status TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements, SavedSlice* ss);






Status CreateTableTensorSliceBuilder(const string& filename, TensorSliceWriter::Builder** builder);

}  

}  


