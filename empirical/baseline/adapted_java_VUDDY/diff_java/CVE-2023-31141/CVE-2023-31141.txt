commit c57f96f62a6ee54f7495902e27c6d74848aa9a24
Author: opensearch-trigger-bot[bot] <98922864+opensearch-trigger-bot[bot]@users.noreply.github.com>
Date:   Fri Mar 10 21:38:52 2023 -0800

    Fix race with eviction when reading from FileCache (#6592) (#6630)
    
    The previous implementation had an inherent race condition where a
    zero-reference count IndexInput read from the cache could be evicted
    before the IndexInput was cloned (and therefore had its reference count
    incremented). Since the IndexInputs are stateful this is very bad. The
    least-recently-used semantics meant that in a properly-configured system
    this would be unlikely since accessing a zero-reference count item would
    move it to be most-recently used and therefore least likely to be
    evicted. However, there was still a latent bug that was possible to
    encounter (see issue #6295).
    
    The only way to fix this, as far as I can see, is to change the cache
    behavior so that fetching an item from the cache atomically
    increments its reference count. This also led to a change to
    TransferManager to ensure that all requests for an item ultimately read
    through the cache to eliminate any possibility of a race. I have
    implement some concurrent unit tests that put the cache into a
    worst-case thrashing scenario to ensure that concurrent access never
    closes an IndexInput while it is still being used.
    
    
    (cherry picked from commit d139ebccbb66b445ac18b4e0c66ca47ef54e60e8)
    
    Signed-off-by: Andrew Ross <andrross@amazon.com>
    Signed-off-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>
    Co-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>

diff --git a/server/src/main/java/org/opensearch/index/store/remote/file/OnDemandBlockSnapshotIndexInput.java b/server/src/main/java/org/opensearch/index/store/remote/file/OnDemandBlockSnapshotIndexInput.java
index 6a873d45319..b3f8ee9c181 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/file/OnDemandBlockSnapshotIndexInput.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/file/OnDemandBlockSnapshotIndexInput.java
@@ -144,13 +144,7 @@ public class OnDemandBlockSnapshotIndexInput extends OnDemandBlockIndexInput {
             .directory(directory)
             .fileName(blockFileName)
             .build();
-        try {
-            return transferManager.fetchBlob(blobFetchRequest);
-        } catch (InterruptedException e) {
-            logger.error("Interrupted while fetching [{}]", blobFetchRequest);
-            Thread.currentThread().interrupt();
-            throw new IllegalStateException(e);
-        }
+        return transferManager.fetchBlob(blobFetchRequest);
     }
 
     @Override
diff --git a/server/src/main/java/org/opensearch/index/store/remote/filecache/FileCache.java b/server/src/main/java/org/opensearch/index/store/remote/filecache/FileCache.java
index 002a6d66e62..2f569341521 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/filecache/FileCache.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/filecache/FileCache.java
@@ -18,7 +18,6 @@ import java.io.UncheckedIOException;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.List;
-import java.util.Map;
 import java.util.function.BiFunction;
 
 import static org.opensearch.index.store.remote.directory.RemoteSnapshotDirectoryFactory.LOCAL_STORE_LOCATION;
@@ -52,21 +51,17 @@ public class FileCache implements RefCountedCache<Path, CachedIndexInput> {
         return theCache.capacity();
     }
 
+    @Override
     public CachedIndexInput put(Path filePath, CachedIndexInput indexInput) {
         return theCache.put(filePath, indexInput);
     }
 
     @Override
-    public void putAll(Map<? extends Path, ? extends CachedIndexInput> m) {
-        theCache.putAll(m);
-    }
-
-    @Override
-    public CachedIndexInput computeIfPresent(
+    public CachedIndexInput compute(
         Path key,
         BiFunction<? super Path, ? super CachedIndexInput, ? extends CachedIndexInput> remappingFunction
     ) {
-        return theCache.computeIfPresent(key, remappingFunction);
+        return theCache.compute(key, remappingFunction);
     }
 
     /**
@@ -91,11 +86,6 @@ public class FileCache implements RefCountedCache<Path, CachedIndexInput> {
         theCache.remove(filePath);
     }
 
-    @Override
-    public void removeAll(Iterable<? extends Path> keys) {
-        theCache.removeAll(keys);
-    }
-
     @Override
     public void clear() {
         theCache.clear();
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizer.java b/server/src/main/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizer.java
deleted file mode 100644
index 2b55377bc17..00000000000
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizer.java
+++ /dev/null
@@ -1,87 +0,0 @@
-/*
- * SPDX-License-Identifier: Apache-2.0
- *
- * The OpenSearch Contributors require contributions made to
- * this file be licensed under the Apache-2.0 license or a
- * compatible open source license.
- */
-
-package org.opensearch.index.store.remote.utils;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.Map;
-import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.ExecutionException;
-
-import org.opensearch.common.CheckedFunction;
-
-/**
- * A utility class which can be used to serialize concurrent invocations and to achieve "invoke simultaneously once at any time"
- * semantic. This class does not implement any concurrency itself. When there is no concurrent access the work will be performed
- * on the calling thread, though the result of that work will be shared with any concurrent requests for the same key.
- *
- * @param <METHOD_PARAM_TYPE> the method parameter type where this method invocation will be linearized
- * @param <RET_TYPE>          return type of the method
- * @opensearch.internal
- */
-class ConcurrentInvocationLinearizer<METHOD_PARAM_TYPE, RET_TYPE> {
-    private final ConcurrentMap<METHOD_PARAM_TYPE, CompletableFuture<RET_TYPE>> invokeOnceCache = new ConcurrentHashMap<>();
-
-    /**
-     * Invokes the given function. If another thread is concurrently invoking the same function, as
-     * identified by the given input, then this call will block and return the result of that
-     * computation. Otherwise it will synchronously invoke the given function and return the result.
-     * @param input The input to uniquely identify this function
-     * @param function The function to invoke
-     * @return The result of the function
-     * @throws InterruptedException thrown if interrupted while blocking
-     * @throws IOException thrown from given function
-     */
-    RET_TYPE linearize(METHOD_PARAM_TYPE input, CheckedFunction<METHOD_PARAM_TYPE, RET_TYPE, IOException> function)
-        throws InterruptedException, IOException {
-        try {
-            return linearizeInternal(input, function).get();
-        } catch (ExecutionException e) {
-            if (e.getCause() instanceof IOException) {
-                throw (IOException) e.getCause();
-            } else if (e.getCause() instanceof RuntimeException) {
-                throw (RuntimeException) e.getCause();
-            } else if (e.getCause() instanceof Error) {
-                throw (Error) e.getCause();
-            }
-            throw new RuntimeException("Unknown exception cause", e.getCause());
-        }
-    }
-
-    // Visible for testing
-    CompletableFuture<RET_TYPE> linearizeInternal(
-        METHOD_PARAM_TYPE input,
-        CheckedFunction<METHOD_PARAM_TYPE, RET_TYPE, IOException> function
-    ) {
-        final CompletableFuture<RET_TYPE> newFuture = new CompletableFuture<>();
-        final CompletableFuture<RET_TYPE> existing = invokeOnceCache.putIfAbsent(input, newFuture);
-        if (existing == null) {
-            // No concurrent work is happening for this key, so need to do the
-            // work and complete the future with the result.
-            try {
-                newFuture.complete(function.apply(input));
-            } catch (Throwable e) {
-                newFuture.completeExceptionally(e);
-            } finally {
-                invokeOnceCache.remove(input);
-            }
-            return newFuture;
-        } else {
-            // Another thread is doing the work, so return the future to its result
-            return existing;
-        }
-    }
-
-    // Visible for testing
-    Map<METHOD_PARAM_TYPE, CompletableFuture<RET_TYPE>> getInvokeOnceCache() {
-        return Collections.unmodifiableMap(invokeOnceCache);
-    }
-}
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/TransferManager.java b/server/src/main/java/org/opensearch/index/store/remote/utils/TransferManager.java
index 6f015fe810d..976827d5827 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/TransferManager.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/utils/TransferManager.java
@@ -22,7 +22,6 @@ import java.io.InputStream;
 import java.io.OutputStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.Objects;
 
 /**
  * This acts as entry point to fetch {@link BlobFetchRequest} and return actual {@link IndexInput}. Utilizes the BlobContainer interface to
@@ -34,12 +33,10 @@ public class TransferManager {
     private static final Logger logger = LogManager.getLogger(TransferManager.class);
 
     private final BlobContainer blobContainer;
-    private final ConcurrentInvocationLinearizer<Path, IndexInput> invocationLinearizer;
     private final FileCache fileCache;
 
     public TransferManager(final BlobContainer blobContainer, final FileCache fileCache) {
         this.blobContainer = blobContainer;
-        this.invocationLinearizer = new ConcurrentInvocationLinearizer<>();
         this.fileCache = fileCache;
     }
 
@@ -48,53 +45,46 @@ public class TransferManager {
      * @param blobFetchRequest to fetch
      * @return future of IndexInput augmented with internal caching maintenance tasks
      */
-    public IndexInput fetchBlob(BlobFetchRequest blobFetchRequest) throws InterruptedException, IOException {
-        final IndexInput indexInput = invocationLinearizer.linearize(
-            blobFetchRequest.getFilePath(),
-            p -> fetchOriginBlob(blobFetchRequest)
-        );
-        return indexInput.clone();
-    }
+    public IndexInput fetchBlob(BlobFetchRequest blobFetchRequest) throws IOException {
+        final Path key = blobFetchRequest.getFilePath();
 
-    /**
-     * Fetches the "origin" IndexInput from the cache, downloading it first if it is
-     * not already cached. This instance must be cloned before using. This method is
-     * accessed through the ConcurrentInvocationLinearizer so read-check-write is
-     * acceptable here
-     */
-    private IndexInput fetchOriginBlob(BlobFetchRequest blobFetchRequest) throws IOException {
-        // check if the origin is already in block cache
-        IndexInput origin = fileCache.computeIfPresent(blobFetchRequest.getFilePath(), (path, cachedIndexInput) -> {
-            if (cachedIndexInput.isClosed()) {
-                // if it's already in the file cache, but closed, open it and replace the original one
+        final IndexInput origin = fileCache.compute(key, (path, cachedIndexInput) -> {
+            if (cachedIndexInput == null) {
                 try {
-                    IndexInput luceneIndexInput = blobFetchRequest.getDirectory().openInput(blobFetchRequest.getFileName(), IOContext.READ);
-                    return new FileCachedIndexInput(fileCache, blobFetchRequest.getFilePath(), luceneIndexInput);
-                } catch (IOException ioe) {
-                    logger.warn("Open index input " + blobFetchRequest.getFilePath() + " got error ", ioe);
-                    // open failed so return null to download the file again
+                    return new FileCachedIndexInput(fileCache, blobFetchRequest.getFilePath(), downloadBlockLocally(blobFetchRequest));
+                } catch (IOException e) {
+                    logger.warn("Failed to download " + blobFetchRequest.getFilePath(), e);
                     return null;
                 }
-
+            } else {
+                if (cachedIndexInput.isClosed()) {
+                    // if it's already in the file cache, but closed, open it and replace the original one
+                    try {
+                        final IndexInput luceneIndexInput = blobFetchRequest.getDirectory()
+                            .openInput(blobFetchRequest.getFileName(), IOContext.READ);
+                        return new FileCachedIndexInput(fileCache, blobFetchRequest.getFilePath(), luceneIndexInput);
+                    } catch (IOException e) {
+                        logger.warn("Failed to open existing file for " + blobFetchRequest.getFilePath(), e);
+                        return null;
+                    }
+                }
+                // already in the cache and ready to be used (open)
+                return cachedIndexInput;
             }
-            // already in the cache and ready to be used (open)
-            return cachedIndexInput;
         });
 
-        if (Objects.isNull(origin)) {
-            // origin is not in file cache, download origin
-
-            // open new origin
-            IndexInput downloaded = downloadBlockLocally(blobFetchRequest);
-
-            // refcount = 0 at the beginning
-            FileCachedIndexInput newOrigin = new FileCachedIndexInput(fileCache, blobFetchRequest.getFilePath(), downloaded);
+        if (origin == null) {
+            throw new IOException("Failed to create IndexInput for " + blobFetchRequest.getFileName());
+        }
 
-            // put origin into file cache
-            fileCache.put(blobFetchRequest.getFilePath(), newOrigin);
-            origin = newOrigin;
+        // Origin was either retrieved from the cache or newly added, either
+        // way the reference count has been incremented by one. We can only
+        // decrement this reference _after_ creating the clone to be returned.
+        try {
+            return origin.clone();
+        } finally {
+            fileCache.decRef(key);
         }
-        return origin;
     }
 
     private IndexInput downloadBlockLocally(BlobFetchRequest blobFetchRequest) throws IOException {
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/LRUCache.java b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/LRUCache.java
index b9a9c063fde..75b28baafe5 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/LRUCache.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/LRUCache.java
@@ -17,7 +17,6 @@ import org.opensearch.index.store.remote.utils.cache.stats.DefaultStatsCounter;
 import org.opensearch.index.store.remote.utils.cache.stats.StatsCounter;
 
 import java.util.HashMap;
-import java.util.Map;
 import java.util.Objects;
 import java.util.concurrent.locks.ReentrantLock;
 import java.util.function.BiFunction;
@@ -137,9 +136,7 @@ class LRUCache<K, V> implements RefCountedCache<K, V> {
                 return null;
             }
             // hit
-            if (node.evictable()) {
-                lru.moveToBack(node);
-            }
+            incRef(key);
             statsCounter.recordHits(key, 1);
             return node.value;
         } finally {
@@ -147,46 +144,21 @@ class LRUCache<K, V> implements RefCountedCache<K, V> {
         }
     }
 
-    /**
-     * If put a new item to the cache, it's zero referenced.
-     * Otherwise, just replace the node with new value and new weight.
-     */
     @Override
     public V put(K key, V value) {
         Objects.requireNonNull(key);
         Objects.requireNonNull(value);
 
-        final long weight = weigher.weightOf(value);
         final ReentrantLock lock = this.lock;
         lock.lock();
         try {
             Node<K, V> node = data.get(key);
             if (node != null) {
                 final V oldValue = node.value;
-                final long oldWeight = node.weight;
-                // update the value and weight
-                node.value = value;
-                node.weight = weight;
-                // update usage
-                final long weightDiff = weight - oldWeight;
-                if (node.refCount > 0) {
-                    activeUsage += weightDiff;
-                }
-                if (node.evictable()) {
-                    lru.moveToBack(node);
-                }
-                usage += weightDiff;
-                // call listeners
-                statsCounter.recordReplacement();
-                listener.onRemoval(new RemovalNotification<>(key, oldValue, RemovalReason.REPLACED));
-                evict();
+                replaceNode(node, value);
                 return oldValue;
             } else {
-                Node<K, V> newNode = new Node<>(key, value, weight);
-                data.put(key, newNode);
-                lru.add(newNode);
-                usage += weight;
-                evict();
+                addNode(key, value);
                 return null;
             }
         } finally {
@@ -195,63 +167,34 @@ class LRUCache<K, V> implements RefCountedCache<K, V> {
     }
 
     @Override
-    public void putAll(Map<? extends K, ? extends V> m) {
-        for (Map.Entry<? extends K, ? extends V> e : m.entrySet())
-            put(e.getKey(), e.getValue());
-    }
-
-    @Override
-    public V computeIfPresent(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {
+    public V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {
         Objects.requireNonNull(key);
+        Objects.requireNonNull(remappingFunction);
         final ReentrantLock lock = this.lock;
         lock.lock();
         try {
-            Node<K, V> node = data.get(key);
-            if (node != null && node.value != null) {
-                V v = remappingFunction.apply(key, node.value);
-                if (v != null) {
-                    final V oldValue = node.value;
-                    final long oldWeight = node.weight;
-                    final long weight = weigher.weightOf(v);
-                    // update the value and weight
-                    node.value = v;
-                    node.weight = weight;
-
-                    // update usage
-                    final long weightDiff = weight - oldWeight;
-                    if (node.evictable()) {
-                        lru.moveToBack(node);
-                    }
-
-                    if (node.refCount > 0) {
-                        activeUsage += weightDiff;
-                    }
-
-                    usage += weightDiff;
-                    statsCounter.recordHits(key, 1);
-                    if (oldValue != node.value) {
-                        statsCounter.recordReplacement();
-                        listener.onRemoval(new RemovalNotification<>(node.key, oldValue, RemovalReason.REPLACED));
-                    }
-                    evict();
-                    return v;
+            final Node<K, V> node = data.get(key);
+            if (node == null) {
+                final V newValue = remappingFunction.apply(key, null);
+                if (newValue == null) {
+                    // Remapping function asked for removal, but nothing to remove
+                    return null;
+                } else {
+                    addNode(key, newValue);
+                    statsCounter.recordMisses(key, 1);
+                    return newValue;
+                }
+            } else {
+                final V newValue = remappingFunction.apply(key, node.value);
+                if (newValue == null) {
+                    removeNode(key);
+                    return null;
                 } else {
-                    // is v is null, remove the item
-                    data.remove(key);
-                    if (node.refCount > 0) {
-                        activeUsage -= node.weight;
-                    }
-                    usage -= node.weight;
-                    if (node.evictable()) {
-                        lru.remove(node);
-                    }
-                    statsCounter.recordRemoval(node.weight);
-                    listener.onRemoval(new RemovalNotification<>(node.key, node.value, RemovalReason.EXPLICIT));
+                    statsCounter.recordHits(key, 1);
+                    replaceNode(node, newValue);
+                    return newValue;
                 }
             }
-
-            statsCounter.recordMisses(key, 1);
-            return null;
         } finally {
             lock.unlock();
         }
@@ -263,30 +206,12 @@ class LRUCache<K, V> implements RefCountedCache<K, V> {
         final ReentrantLock lock = this.lock;
         lock.lock();
         try {
-            Node<K, V> node = data.remove(key);
-            if (node != null) {
-                if (node.refCount > 0) {
-                    activeUsage -= node.weight;
-                }
-                usage -= node.weight;
-                if (node.evictable()) {
-                    lru.remove(node);
-                }
-                statsCounter.recordRemoval(node.weight);
-                listener.onRemoval(new RemovalNotification<>(node.key, node.value, RemovalReason.EXPLICIT));
-            }
+            removeNode(key);
         } finally {
             lock.unlock();
         }
     }
 
-    @Override
-    public void removeAll(Iterable<? extends K> keys) {
-        for (K key : keys) {
-            remove(key);
-        }
-    }
-
     @Override
     public void clear() {
         final ReentrantLock lock = this.lock;
@@ -409,11 +334,56 @@ class LRUCache<K, V> implements RefCountedCache<K, V> {
         }
     }
 
-    boolean hasOverflowed() {
+    private void addNode(K key, V value) {
+        final long weight = weigher.weightOf(value);
+        Node<K, V> newNode = new Node<>(key, value, weight);
+        data.put(key, newNode);
+        usage += weight;
+        incRef(key);
+        evict();
+    }
+
+    private void replaceNode(Node<K, V> node, V newValue) {
+        if (node.value != newValue) { // replace if new value is not the same instance as existing value
+            final V oldValue = node.value;
+            final long oldWeight = node.weight;
+            final long newWeight = weigher.weightOf(newValue);
+            // update the value and weight
+            node.value = newValue;
+            node.weight = newWeight;
+            // update usage
+            final long weightDiff = newWeight - oldWeight;
+            if (node.refCount > 0) {
+                activeUsage += weightDiff;
+            }
+            usage += weightDiff;
+            statsCounter.recordReplacement();
+            listener.onRemoval(new RemovalNotification<>(node.key, oldValue, RemovalReason.REPLACED));
+        }
+        incRef(node.key);
+        evict();
+    }
+
+    private void removeNode(K key) {
+        Node<K, V> node = data.remove(key);
+        if (node != null) {
+            if (node.refCount > 0) {
+                activeUsage -= node.weight;
+            }
+            usage -= node.weight;
+            if (node.evictable()) {
+                lru.remove(node);
+            }
+            statsCounter.recordRemoval(node.weight);
+            listener.onRemoval(new RemovalNotification<>(node.key, node.value, RemovalReason.EXPLICIT));
+        }
+    }
+
+    private boolean hasOverflowed() {
         return usage >= capacity;
     }
 
-    void evict() {
+    private void evict() {
         // Attempts to evict entries from the cache if it exceeds the maximum
         // capacity.
         while (hasOverflowed()) {
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/RefCountedCache.java b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/RefCountedCache.java
index 7964e41b4f4..bbb37dc57ae 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/RefCountedCache.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/RefCountedCache.java
@@ -10,14 +10,13 @@ package org.opensearch.index.store.remote.utils.cache;
 
 import org.opensearch.index.store.remote.utils.cache.stats.CacheStats;
 
-import java.util.Map;
 import java.util.function.BiFunction;
 
 /**
  * Custom Cache which support typical cache operations (put, get, ...) and it support reference counting per individual key which might
  * change eviction behavior
  * @param <K> type of the key
- * @param <V> type of th value
+ * @param <V> type of the value
  *
  * @opensearch.internal
  */
@@ -25,7 +24,8 @@ public interface RefCountedCache<K, V> {
 
     /**
      * Returns the value associated with {@code key} in this cache, or {@code null} if there is no
-     * cached value for {@code key}.
+     * cached value for {@code key}. Retrieving an item automatically increases its reference
+     * count.
      */
     V get(K key);
 
@@ -35,36 +35,28 @@ public interface RefCountedCache<K, V> {
      */
     V put(K key, V value);
 
-    /**
-     * Copies all the mappings from the specified map to the cache. The effect of this call is
-     * equivalent to that of calling {@code put(k, v)} on this map once for each mapping from key
-     * {@code k} to value {@code v} in the specified map. The behavior of this operation is undefined
-     * if the specified map is modified while the operation is in progress.
-     */
-    void putAll(Map<? extends K, ? extends V> m);
-
     /**
      * If the specified key is already associated with a value, attempts to update its value using the given mapping
-     * function and enters the new value into this map unless null.
-     *
-     * If the specified key is NOT already associated with a value, return null without applying the mapping function.
-     *
+     * function and enters the new value. If the mapping function returns null the item is removed from the
+     * cache, regardless of its reference count. If the mapping function returns non-null the value is updated.
+     * The new entry will have the reference count of the previous entry plus one, as this method automatically
+     * increases the reference count by one when it returns the newly mapped value.
+     * <p>
+     * If the specified key is NOT already associated with a value, then the value of the remapping function
+     * will be associated with the given key, and its reference count will be set to one. If the remapping function
+     * returns null then nothing is done.
+     * <p>
      * The remappingFunction method for a given key will be invoked at most once.
      */
-    V computeIfPresent(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction);
+    V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction);
 
     /**
-     * Discards any cached value for key {@code key}.
+     * Discards any cached value for key {@code key}, regardless of reference count.
      */
     void remove(K key);
 
     /**
-     * Discards any cached values for keys {@code keys}.
-     */
-    void removeAll(Iterable<? extends K> keys);
-
-    /**
-     * Discards all entries in the cache.
+     * Discards all entries in the cache, regardless of reference count.
      */
     void clear();
 
@@ -83,6 +75,11 @@ public interface RefCountedCache<K, V> {
      */
     void decRef(K key);
 
+    /**
+     * Removes all cache entries with a reference count of zero, regardless of current capacity.
+     *
+     * @return The total weight of all removed entries.
+     */
     long prune();
 
     /**
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/SegmentedCache.java b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/SegmentedCache.java
index 04b0581b41f..42e44aa5f6a 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/SegmentedCache.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/SegmentedCache.java
@@ -13,7 +13,6 @@ import org.opensearch.common.cache.RemovalNotification;
 import org.opensearch.common.cache.Weigher;
 import org.opensearch.index.store.remote.utils.cache.stats.CacheStats;
 
-import java.util.Map;
 import java.util.Objects;
 import java.util.function.BiFunction;
 
@@ -91,15 +90,9 @@ public class SegmentedCache<K, V> implements RefCountedCache<K, V> {
     }
 
     @Override
-    public void putAll(Map<? extends K, ? extends V> m) {
-        for (Map.Entry<? extends K, ? extends V> e : m.entrySet())
-            put(e.getKey(), e.getValue());
-    }
-
-    @Override
-    public V computeIfPresent(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {
+    public V compute(K key, BiFunction<? super K, ? super V, ? extends V> remappingFunction) {
         if (key == null || remappingFunction == null) throw new NullPointerException();
-        return segmentFor(key).computeIfPresent(key, remappingFunction);
+        return segmentFor(key).compute(key, remappingFunction);
     }
 
     @Override
@@ -108,12 +101,6 @@ public class SegmentedCache<K, V> implements RefCountedCache<K, V> {
         segmentFor(key).remove(key);
     }
 
-    @Override
-    public void removeAll(Iterable<? extends K> keys) {
-        for (K k : keys)
-            remove(k);
-    }
-
     @Override
     public void clear() {
         for (RefCountedCache<K, V> cache : table) {
diff --git a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/stats/StatsCounter.java b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/stats/StatsCounter.java
index 680dc441252..b096bb8d652 100644
--- a/server/src/main/java/org/opensearch/index/store/remote/utils/cache/stats/StatsCounter.java
+++ b/server/src/main/java/org/opensearch/index/store/remote/utils/cache/stats/StatsCounter.java
@@ -43,7 +43,7 @@ public interface StatsCounter<K> {
      * Records the explicit removal of an entry from the cache. This should only been called when an entry is
      * removed as a result of manual
      * {@link RefCountedCache#remove(Object)}
-     * {@link RefCountedCache#computeIfPresent(Object, BiFunction)}
+     * {@link RefCountedCache#compute(Object, BiFunction)}
      *
      * @param weight the weight of the removed entry
      */
@@ -53,7 +53,7 @@ public interface StatsCounter<K> {
      * Records the replacement of an entry from the cache. This should only been called when an entry is
      * replaced as a result of manual
      * {@link RefCountedCache#put(Object, Object)}
-     * {@link RefCountedCache#computeIfPresent(Object, BiFunction)}
+     * {@link RefCountedCache#compute(Object, BiFunction)}
      */
     void recordReplacement();
 
diff --git a/server/src/test/java/org/opensearch/index/store/remote/filecache/FileCacheTests.java b/server/src/test/java/org/opensearch/index/store/remote/filecache/FileCacheTests.java
index 30f391ce145..72ac9837537 100644
--- a/server/src/test/java/org/opensearch/index/store/remote/filecache/FileCacheTests.java
+++ b/server/src/test/java/org/opensearch/index/store/remote/filecache/FileCacheTests.java
@@ -19,10 +19,7 @@ import org.opensearch.test.OpenSearchTestCase;
 import java.io.IOException;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 
 public class FileCacheTests extends OpenSearchTestCase {
     // need concurrency level to be static to make these tests more deterministic because capacity per segment is dependent on
@@ -90,36 +87,23 @@ public class FileCacheTests extends OpenSearchTestCase {
         });
     }
 
-    public void testComputeIfPresent() {
+    public void testCompute() {
         FileCache fileCache = createFileCache(GIGA_BYTES);
         Path path = createPath("0");
         fileCache.put(path, new FakeIndexInput(8 * MEGA_BYTES));
         fileCache.incRef(path);
-        fileCache.computeIfPresent(path, (p, i) -> null);
+        fileCache.compute(path, (p, i) -> null);
         // item will be removed
         assertEquals(fileCache.size(), 0);
     }
 
-    public void testComputeIfPresentThrowException() {
+    public void testComputeThrowException() {
         assertThrows(NullPointerException.class, () -> {
             FileCache fileCache = createFileCache(GIGA_BYTES);
-            fileCache.computeIfPresent(null, null);
+            fileCache.compute(null, null);
         });
     }
 
-    public void testPutAll() {
-        FileCache fileCache = createFileCache(GIGA_BYTES);
-        Map<Path, CachedIndexInput> blockMaps = new HashMap<>();
-        for (int i = 0; i < 4; i++) {
-            blockMaps.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
-        }
-        fileCache.putAll(blockMaps);
-        // verify all blocks are put into file cache
-        for (int i = 0; i < 4; i++) {
-            assertNotNull(fileCache.get(createPath(Integer.toString(i))));
-        }
-    }
-
     public void testRemove() {
         FileCache fileCache = createFileCache(GIGA_BYTES);
         for (int i = 0; i < 4; i++) {
@@ -141,33 +125,21 @@ public class FileCacheTests extends OpenSearchTestCase {
         });
     }
 
-    public void testRemoveAll() {
-        FileCache fileCache = createFileCache(GIGA_BYTES);
-        List<Path> blockPathList = new ArrayList<>();
-        for (int i = 0; i < 4; i++) {
-            Path blockPath = createPath(Integer.toString(i));
-            fileCache.put(blockPath, new FakeIndexInput(8 * MEGA_BYTES));
-            blockPathList.add(blockPath);
-        }
-        fileCache.removeAll(blockPathList);
-        assertEquals(fileCache.size(), 0);
-    }
-
     public void testIncDecRef() {
         FileCache fileCache = createFileCache(GIGA_BYTES);
         for (int i = 0; i < 4; i++) {
             fileCache.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
-            fileCache.incRef(createPath(Integer.toString(i)));
         }
 
         // try to evict previous IndexInput
         for (int i = 1000; i < 3000; i++) {
-            fileCache.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
+            putAndDecRef(fileCache, i, 8 * MEGA_BYTES);
         }
 
         // IndexInput with refcount greater than 0 will not be evicted
         for (int i = 0; i < 4; i++) {
             assertNotNull(fileCache.get(createPath(Integer.toString(i))));
+            fileCache.decRef(createPath(Integer.toString(i)));
         }
 
         // decrease ref
@@ -177,7 +149,7 @@ public class FileCacheTests extends OpenSearchTestCase {
 
         // try to evict previous IndexInput again
         for (int i = 3000; i < 5000; i++) {
-            fileCache.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
+            putAndDecRef(fileCache, i, 8 * MEGA_BYTES);
         }
 
         for (int i = 0; i < 4; i++) {
@@ -218,7 +190,7 @@ public class FileCacheTests extends OpenSearchTestCase {
     public void testPrune() {
         FileCache fileCache = createFileCache(GIGA_BYTES);
         for (int i = 0; i < 4; i++) {
-            fileCache.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
+            putAndDecRef(fileCache, i, 8 * MEGA_BYTES);
         }
         // before prune
         assertEquals(fileCache.size(), 4);
@@ -229,11 +201,10 @@ public class FileCacheTests extends OpenSearchTestCase {
     }
 
     public void testUsage() {
-        // edge case, all Indexinput will be evicted as soon as they are put into file cache
         FileCache fileCache = FileCacheFactory.createConcurrentLRUFileCache(16 * MEGA_BYTES, 1);
-        fileCache.put(createPath("0"), new FakeIndexInput(16 * MEGA_BYTES));
+        putAndDecRef(fileCache, 0, 16 * MEGA_BYTES);
 
-        CacheUsage expectedCacheUsage = new CacheUsage(0, 0);
+        CacheUsage expectedCacheUsage = new CacheUsage(16 * MEGA_BYTES, 0);
         CacheUsage realCacheUsage = fileCache.usage();
         assertEquals(expectedCacheUsage.activeUsage(), realCacheUsage.activeUsage());
         assertEquals(expectedCacheUsage.usage(), realCacheUsage.usage());
@@ -255,7 +226,7 @@ public class FileCacheTests extends OpenSearchTestCase {
 
         // do some eviction here
         for (int i = 0; i < 2000; i++) {
-            fileCache.put(createPath(Integer.toString(i)), new FakeIndexInput(8 * MEGA_BYTES));
+            putAndDecRef(fileCache, i, 8 * MEGA_BYTES);
         }
         assertTrue(fileCache.stats().evictionCount() > 0);
         assertTrue(fileCache.stats().evictionWeight() > 0);
@@ -266,7 +237,6 @@ public class FileCacheTests extends OpenSearchTestCase {
         String nodeId = "0";
         String indexName = "test-index";
         String shardId = "0";
-        NodeEnvironment.NodePath fileCacheNodePath = new NodeEnvironment.NodePath(path);
         createFile(nodeId, indexName, shardId, "test.0");
         FileCache fileCache = createFileCache(GIGA_BYTES);
         assertEquals(0, fileCache.usage().usage());
@@ -275,6 +245,12 @@ public class FileCacheTests extends OpenSearchTestCase {
         assertTrue(fileCache.usage().usage() > 0);
     }
 
+    private void putAndDecRef(FileCache cache, int path, long indexInputSize) {
+        final Path key = createPath(Integer.toString(path));
+        cache.put(key, new FakeIndexInput(indexInputSize));
+        cache.decRef(key);
+    }
+
     final class FakeIndexInput extends CachedIndexInput {
 
         private final long length;
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizerTests.java b/server/src/test/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizerTests.java
deleted file mode 100644
index 5538b771846..00000000000
--- a/server/src/test/java/org/opensearch/index/store/remote/utils/ConcurrentInvocationLinearizerTests.java
+++ /dev/null
@@ -1,122 +0,0 @@
-/*
- * SPDX-License-Identifier: Apache-2.0
- *
- * The OpenSearch Contributors require contributions made to
- * this file be licensed under the Apache-2.0 license or a
- * compatible open source license.
- */
-
-package org.opensearch.index.store.remote.utils;
-
-import org.hamcrest.MatcherAssert;
-import org.junit.After;
-import org.junit.Before;
-import org.opensearch.test.OpenSearchTestCase;
-
-import java.io.IOException;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-
-import static org.hamcrest.Matchers.anEmptyMap;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class ConcurrentInvocationLinearizerTests extends OpenSearchTestCase {
-    private ExecutorService executorService;
-
-    @Before
-    public void setup() {
-        executorService = Executors.newSingleThreadExecutor();
-    }
-
-    public void testLinearizeShouldNotInvokeMethodMoreThanOnce() throws Exception {
-        final ConcurrentInvocationLinearizer<String, String> invocationLinearizer = new ConcurrentInvocationLinearizer<>();
-        final CountDownLatch startLatch = new CountDownLatch(1);
-        final CountDownLatch finishLatch = new CountDownLatch(1);
-
-        final Future<Future<String>> first = executorService.submit(() -> invocationLinearizer.linearizeInternal("input", s -> {
-            startLatch.countDown();
-            try {
-                finishLatch.await();
-            } catch (InterruptedException e) {
-                throw new AssertionError(e);
-            }
-            return "expected";
-        }));
-
-        startLatch.await(); // Wait for first caller to start work
-        final Future<String> second = invocationLinearizer.linearizeInternal("input", s -> { throw new AssertionError(); });
-        final Future<String> third = invocationLinearizer.linearizeInternal("input", s -> { throw new AssertionError(); });
-        finishLatch.countDown(); // Unblock first caller
-        MatcherAssert.assertThat(first.get().get(), equalTo("expected"));
-        MatcherAssert.assertThat(second.get(), equalTo("expected"));
-        MatcherAssert.assertThat(third.get(), equalTo("expected"));
-        MatcherAssert.assertThat(invocationLinearizer.getInvokeOnceCache(), is(anEmptyMap()));
-    }
-
-    public void testLinearizeSharesFailures() throws Exception {
-        final ConcurrentInvocationLinearizer<String, String> invocationLinearizer = new ConcurrentInvocationLinearizer<>();
-        final CountDownLatch startLatch = new CountDownLatch(1);
-        final CountDownLatch finishLatch = new CountDownLatch(1);
-
-        final Future<Future<String>> first = executorService.submit(() -> invocationLinearizer.linearizeInternal("input", s -> {
-            startLatch.countDown();
-            try {
-                finishLatch.await();
-            } catch (InterruptedException e) {
-                throw new AssertionError(e);
-            }
-            throw new IOException("io exception");
-        }));
-
-        startLatch.await(); // Wait for first caller to start work
-        final Future<String> second = invocationLinearizer.linearizeInternal("input", s -> { throw new AssertionError(); });
-        finishLatch.countDown(); // Unblock first caller
-        final ExecutionException e1 = assertThrows(ExecutionException.class, () -> first.get().get());
-        MatcherAssert.assertThat(e1.getCause(), instanceOf(IOException.class));
-        final ExecutionException e2 = assertThrows(ExecutionException.class, second::get);
-        MatcherAssert.assertThat(e2.getCause(), instanceOf(IOException.class));
-        MatcherAssert.assertThat(invocationLinearizer.getInvokeOnceCache(), is(anEmptyMap()));
-    }
-
-    public void testLinearizeShouldLeaveCacheEmptyEvenWhenFutureFail() {
-        ConcurrentInvocationLinearizer<String, String> invocationLinearizer = new ConcurrentInvocationLinearizer<>();
-        assertThrows(
-            RuntimeException.class,
-            () -> invocationLinearizer.linearize("input", s -> { throw new RuntimeException("exception"); })
-        );
-        MatcherAssert.assertThat("Expected nothing to be cached on failure", invocationLinearizer.getInvokeOnceCache(), is(anEmptyMap()));
-    }
-
-    public void testExceptionHandling() {
-        final ConcurrentInvocationLinearizer<String, String> invocationLinearizer = new ConcurrentInvocationLinearizer<>();
-        assertThrows(
-            RuntimeException.class,
-            () -> invocationLinearizer.linearize("input", s -> { throw new RuntimeException("exception"); })
-        );
-        assertThrows(IOException.class, () -> invocationLinearizer.linearize("input", s -> { throw new IOException("exception"); }));
-        assertThrows(AssertionError.class, () -> invocationLinearizer.linearize("input", s -> { throw new AssertionError("exception"); }));
-        final RuntimeException e = assertThrows(
-            RuntimeException.class,
-            () -> invocationLinearizer.linearize("input", s -> { throw sneakyThrow(new TestCheckedException()); })
-        );
-        MatcherAssert.assertThat(e.getCause(), instanceOf(TestCheckedException.class));
-    }
-
-    @After
-    public void cleanUp() {
-        executorService.shutdownNow();
-        terminate(executorService);
-    }
-
-    // Some unholy hackery with generics to trick the compiler into throwing an undeclared checked exception
-    private static <E extends Throwable> E sneakyThrow(Throwable e) throws E {
-        throw (E) e;
-    }
-
-    private static class TestCheckedException extends Exception {}
-}
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/TransferManagerTests.java b/server/src/test/java/org/opensearch/index/store/remote/utils/TransferManagerTests.java
index dd1cbe1bed5..f3049c504f2 100644
--- a/server/src/test/java/org/opensearch/index/store/remote/utils/TransferManagerTests.java
+++ b/server/src/test/java/org/opensearch/index/store/remote/utils/TransferManagerTests.java
@@ -32,12 +32,17 @@ import org.opensearch.test.OpenSearchTestCase;
 import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;
 
 import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.mockito.ArgumentMatchers.anyLong;
+import static org.mockito.ArgumentMatchers.eq;
 import static org.mockito.Mockito.doAnswer;
+import static org.mockito.Mockito.doThrow;
 import static org.mockito.Mockito.mock;
 
 @ThreadLeakFilters(filters = CleanerDaemonThreadLeakFilter.class)
 public class TransferManagerTests extends OpenSearchTestCase {
-    private final FileCache fileCache = FileCacheFactory.createConcurrentLRUFileCache(1024 * 1024 * 16, 1);
+    private static final int EIGHT_MB = 1024 * 1024 * 8;
+    private final FileCache fileCache = FileCacheFactory.createConcurrentLRUFileCache(EIGHT_MB * 2, 1);
     private MMapDirectory directory;
     private BlobContainer blobContainer;
     private TransferManager transferManager;
@@ -47,7 +52,7 @@ public class TransferManagerTests extends OpenSearchTestCase {
         super.setUp();
         directory = new MMapDirectory(createTempDir(), SimpleFSLockFactory.INSTANCE);
         blobContainer = mock(BlobContainer.class);
-        doAnswer(i -> new ByteArrayInputStream(new byte[] { 0, 1, 2, 3, 4, 5, 6, 7 })).when(blobContainer).readBlob("blob", 0, 8);
+        doAnswer(i -> new ByteArrayInputStream(createData())).when(blobContainer).readBlob(eq("blob"), anyLong(), anyLong());
         transferManager = new TransferManager(blobContainer, fileCache);
     }
 
@@ -56,20 +61,29 @@ public class TransferManagerTests extends OpenSearchTestCase {
         super.tearDown();
     }
 
+    private static byte[] createData() {
+        final byte[] data = new byte[EIGHT_MB];
+        data[EIGHT_MB - 1] = 7;
+        return data;
+    }
+
     public void testSingleAccess() throws Exception {
-        try (IndexInput i = fetchBlob()) {
-            i.seek(7);
-            MatcherAssert.assertThat(i.readByte(), equalTo((byte) 7));
+        try (IndexInput i = fetchBlobWithName("file")) {
+            assertIndexInputIsFunctional(i);
+            MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo((long) EIGHT_MB));
         }
+        MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo(0L));
+        MatcherAssert.assertThat(fileCache.usage().usage(), equalTo((long) EIGHT_MB));
     }
 
     public void testConcurrentAccess() throws Exception {
         // Kick off multiple threads that all concurrently request the same resource
+        final String blobname = "file";
         final ExecutorService testRunner = Executors.newFixedThreadPool(8);
         try {
             final List<Future<IndexInput>> futures = new ArrayList<>();
             for (int i = 0; i < 8; i++) {
-                futures.add(testRunner.submit(this::fetchBlob));
+                futures.add(testRunner.submit(() -> fetchBlobWithName(blobname)));
             }
             // Wait for all threads to complete
             for (Future<IndexInput> future : futures) {
@@ -80,19 +94,92 @@ public class TransferManagerTests extends OpenSearchTestCase {
             // result in EOFExceptions and/or NPEs.
             for (Future<IndexInput> future : futures) {
                 try (IndexInput i = future.get()) {
-                    i.seek(7);
-                    MatcherAssert.assertThat(i.readByte(), equalTo((byte) 7));
+                    assertIndexInputIsFunctional(i);
                 }
             }
         } finally {
-            testRunner.shutdown();
-            assertTrue(testRunner.awaitTermination(1, TimeUnit.SECONDS));
+            assertTrue(terminate(testRunner));
+        }
+    }
+
+    public void testFetchBlobWithConcurrentCacheEvictions() throws Exception {
+        // Submit 256 tasks to an executor with 16 threads that will each randomly
+        // request one of eight blobs. Given that the cache can only hold two
+        // blobs this will lead to a huge amount of contention and thrashing.
+        final ExecutorService testRunner = Executors.newFixedThreadPool(16);
+        try {
+            final List<Future<?>> futures = new ArrayList<>();
+            for (int i = 0; i < 256; i++) {
+                // request an index input and immediately close it
+                final String blobname = "blob-" + randomIntBetween(0, 7);
+                futures.add(testRunner.submit(() -> {
+                    try {
+                        try (IndexInput indexInput = fetchBlobWithName(blobname)) {
+                            assertIndexInputIsFunctional(indexInput);
+                        }
+                    } catch (Exception e) {
+                        throw new AssertionError(e);
+                    }
+                }));
+            }
+            // Wait for all threads to complete
+            for (Future<?> future : futures) {
+                future.get(10, TimeUnit.SECONDS);
+            }
+        } finally {
+            assertTrue(terminate(testRunner));
         }
+        MatcherAssert.assertThat("Expected many evictions to happen", fileCache.stats().evictionCount(), greaterThan(0L));
     }
 
-    private IndexInput fetchBlob() throws InterruptedException, IOException {
+    public void testUsageExceedsCapacity() throws Exception {
+        // Fetch resources that exceed the configured capacity of the cache and assert that the
+        // returned IndexInputs are still functional.
+        try (IndexInput i1 = fetchBlobWithName("1"); IndexInput i2 = fetchBlobWithName("2"); IndexInput i3 = fetchBlobWithName("3")) {
+            assertIndexInputIsFunctional(i1);
+            assertIndexInputIsFunctional(i2);
+            assertIndexInputIsFunctional(i3);
+            MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo((long) EIGHT_MB * 3));
+            MatcherAssert.assertThat(fileCache.usage().usage(), equalTo((long) EIGHT_MB * 3));
+        }
+        MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo(0L));
+        MatcherAssert.assertThat(fileCache.usage().usage(), equalTo((long) EIGHT_MB * 3));
+        // Fetch another resource which will trigger an eviction
+        try (IndexInput i1 = fetchBlobWithName("1")) {
+            assertIndexInputIsFunctional(i1);
+            MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo((long) EIGHT_MB));
+            MatcherAssert.assertThat(fileCache.usage().usage(), equalTo((long) EIGHT_MB));
+        }
+        MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo(0L));
+        MatcherAssert.assertThat(fileCache.usage().usage(), equalTo((long) EIGHT_MB));
+    }
+
+    public void testDownloadFails() throws Exception {
+        doThrow(new IOException("Expected test exception")).when(blobContainer).readBlob(eq("failure-blob"), anyLong(), anyLong());
+        expectThrows(
+            IOException.class,
+            () -> transferManager.fetchBlob(
+                BlobFetchRequest.builder()
+                    .blobName("failure-blob")
+                    .position(0)
+                    .fileName("file")
+                    .directory(directory)
+                    .length(EIGHT_MB)
+                    .build()
+            )
+        );
+        MatcherAssert.assertThat(fileCache.usage().activeUsage(), equalTo(0L));
+        MatcherAssert.assertThat(fileCache.usage().usage(), equalTo(0L));
+    }
+
+    private IndexInput fetchBlobWithName(String blobname) throws IOException {
         return transferManager.fetchBlob(
-            BlobFetchRequest.builder().blobName("blob").position(0).fileName("file").directory(directory).length(8).build()
+            BlobFetchRequest.builder().blobName("blob").position(0).fileName(blobname).directory(directory).length(EIGHT_MB).build()
         );
     }
+
+    private static void assertIndexInputIsFunctional(IndexInput indexInput) throws IOException {
+        indexInput.seek(EIGHT_MB - 1);
+        MatcherAssert.assertThat(indexInput.readByte(), equalTo((byte) 7));
+    }
 }
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/cache/LRUCacheTests.java b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/LRUCacheTests.java
new file mode 100644
index 00000000000..47cb8000b6c
--- /dev/null
+++ b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/LRUCacheTests.java
@@ -0,0 +1,15 @@
+/*
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * The OpenSearch Contributors require contributions made to
+ * this file be licensed under the Apache-2.0 license or a
+ * compatible open source license.
+ */
+
+package org.opensearch.index.store.remote.utils.cache;
+
+public class LRUCacheTests extends RefCountedCacheTestCase {
+    public LRUCacheTests() {
+        super(new LRUCache<>(CAPACITY, n -> {}, value -> value));
+    }
+}
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTestCase.java b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTestCase.java
new file mode 100644
index 00000000000..59657eebc44
--- /dev/null
+++ b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTestCase.java
@@ -0,0 +1,203 @@
+/*
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * The OpenSearch Contributors require contributions made to
+ * this file be licensed under the Apache-2.0 license or a
+ * compatible open source license.
+ */
+
+package org.opensearch.index.store.remote.utils.cache;
+
+import org.opensearch.test.OpenSearchTestCase;
+
+abstract class RefCountedCacheTestCase extends OpenSearchTestCase {
+    static final int CAPACITY = 100;
+
+    private final RefCountedCache<String, Long> refCountedCache;
+
+    protected RefCountedCacheTestCase(RefCountedCache<String, Long> refCountedCache) {
+        this.refCountedCache = refCountedCache;
+    }
+
+    public void testBasicGetAndPutAndRemove() {
+        assertNull(refCountedCache.get("1"));
+        refCountedCache.put("1", 10L);
+        assertEquals(10L, (long) refCountedCache.get("1"));
+        refCountedCache.remove("1");
+        assertNull(refCountedCache.get("1"));
+    }
+
+    public void testUsageWithIncrementAndDecrement() {
+        refCountedCache.put("1", 10L);
+        assertEquals(10L, refCountedCache.usage().usage());
+        assertEquals(10L, refCountedCache.usage().activeUsage());
+
+        refCountedCache.decRef("1");
+        assertEquals(10L, refCountedCache.usage().usage());
+        assertEquals(0L, refCountedCache.usage().activeUsage());
+
+        refCountedCache.incRef("1");
+        assertEquals(10L, refCountedCache.usage().usage());
+        assertEquals(10L, refCountedCache.usage().activeUsage());
+    }
+
+    public void testEviction() {
+        for (int i = 1; i <= 5; i++) {
+            final String key = Integer.toString(i);
+            refCountedCache.put(key, 25L);
+            refCountedCache.decRef(key);
+        }
+        assertNull(refCountedCache.get("1"));
+        assertNull(refCountedCache.get("2"));
+        assertNotNull(refCountedCache.get("3"));
+        assertNotNull(refCountedCache.get("4"));
+        assertNotNull(refCountedCache.get("5"));
+
+        assertEquals(75L, refCountedCache.usage().usage());
+        assertEquals(75L, refCountedCache.usage().activeUsage());
+    }
+
+    public void testComputeRemoveWhenExists() {
+        refCountedCache.put("1", 25L);
+        refCountedCache.decRef("1");
+        assertEquals(0, refCountedCache.usage().activeUsage());
+        assertEquals(25L, refCountedCache.usage().usage());
+
+        assertNull(refCountedCache.compute("1", (k, v) -> null));
+        assertNull(refCountedCache.get("1"));
+        assertEquals(0, refCountedCache.usage().activeUsage());
+        assertEquals(0L, refCountedCache.usage().usage());
+    }
+
+    public void testComputeRemoveWhenNotExists() {
+        assertUsage(0, 0);
+        assertNull(refCountedCache.compute("1", (k, v) -> null));
+        assertNull(refCountedCache.get("1"));
+        assertUsage(0, 0);
+    }
+
+    public void testComputeRemapExists() {
+        assertUsage(0, 0);
+        refCountedCache.put("1", 25L);
+        refCountedCache.decRef("1");
+        assertUsage(25, 0);
+
+        final long newValue = refCountedCache.compute("1", (k, v) -> v + 5);
+        assertEquals(30L, newValue);
+        assertUsage(30, 30);
+
+        refCountedCache.decRef("1");
+        assertUsage(30, 0);
+
+        assertEquals(30L, (long) refCountedCache.get("1"));
+    }
+
+    public void testComputeRemapNotExists() {
+        assertUsage(0, 0);
+        final long newValue = refCountedCache.compute("1", (k, v) -> 30L);
+        assertEquals(30L, newValue);
+        assertUsage(30, 30);
+
+        refCountedCache.decRef("1");
+        assertUsage(30, 0);
+
+        assertEquals(30L, (long) refCountedCache.get("1"));
+    }
+
+    public void testActiveUsageGreaterThanCapacity() {
+        for (int i = 1; i <= 5; i++) {
+            final String key = Integer.toString(i);
+            refCountedCache.put(key, 25L);
+        }
+        assertEquals(125L, refCountedCache.usage().usage());
+        assertEquals(125L, refCountedCache.usage().activeUsage());
+    }
+
+    public void testReferenceCountingItemsThatDoNotExist() {
+        assertNull(refCountedCache.get("1"));
+        assertUsage(0, 0);
+        refCountedCache.incRef("1");
+        assertNull(refCountedCache.get("1"));
+        assertUsage(0, 0);
+        refCountedCache.decRef("1");
+        assertNull(refCountedCache.get("1"));
+        assertEquals(0L, refCountedCache.usage().usage());
+        assertEquals(0L, refCountedCache.usage().activeUsage());
+    }
+
+    public void testPrune() {
+        refCountedCache.put("1", 10L);
+        refCountedCache.decRef("1");
+        refCountedCache.put("2", 10L);
+        refCountedCache.decRef("2");
+        refCountedCache.put("3", 10L);
+
+        assertEquals(20L, refCountedCache.prune());
+        assertNull(refCountedCache.get("1"));
+        assertNull(refCountedCache.get("2"));
+        assertEquals(10L, (long) refCountedCache.get("3"));
+    }
+
+    public void testStats() {
+        assertEquals(0, refCountedCache.stats().hitCount());
+        refCountedCache.put("1", 1L);
+        refCountedCache.get("1");
+        assertEquals(1, refCountedCache.stats().hitCount());
+
+        assertEquals(0, refCountedCache.stats().replaceCount());
+        refCountedCache.put("1", 2L);
+        assertEquals(1, refCountedCache.stats().replaceCount());
+        assertEquals(1, refCountedCache.stats().hitCount());
+
+        assertEquals(0, refCountedCache.stats().evictionCount());
+        refCountedCache.put("2", 80L);
+        refCountedCache.decRef("2");
+        refCountedCache.put("3", 80L);
+        assertEquals(1, refCountedCache.stats().evictionCount());
+
+        assertEquals(0, refCountedCache.stats().missCount());
+        assertNull(refCountedCache.get("2"));
+        assertEquals(1, refCountedCache.stats().missCount());
+
+        assertEquals(0, refCountedCache.stats().removeCount());
+        refCountedCache.remove("3");
+        assertEquals(1, refCountedCache.stats().removeCount());
+    }
+
+    public void testComputeStats() {
+        refCountedCache.compute("1", (k, v) -> null);
+        assertEquals(0, refCountedCache.stats().missCount());
+        assertEquals(0, refCountedCache.stats().hitCount());
+        assertEquals(0, refCountedCache.stats().replaceCount());
+        assertEquals(0, refCountedCache.stats().removeCount());
+
+        refCountedCache.compute("1", (k, v) -> 10L);
+        assertEquals(1, refCountedCache.stats().missCount());
+        assertEquals(0, refCountedCache.stats().hitCount());
+        assertEquals(0, refCountedCache.stats().replaceCount());
+        assertEquals(0, refCountedCache.stats().removeCount());
+
+        refCountedCache.compute("1", (k, v) -> 10L);
+        assertEquals(1, refCountedCache.stats().missCount());
+        assertEquals(1, refCountedCache.stats().hitCount());
+        assertEquals(0, refCountedCache.stats().replaceCount());
+        assertEquals(0, refCountedCache.stats().removeCount());
+
+        refCountedCache.compute("1", (k, v) -> 20L);
+        assertEquals(1, refCountedCache.stats().missCount());
+        assertEquals(2, refCountedCache.stats().hitCount());
+        assertEquals(1, refCountedCache.stats().replaceCount());
+        assertEquals(0, refCountedCache.stats().removeCount());
+
+        refCountedCache.compute("1", (k, v) -> null);
+        assertEquals(1, refCountedCache.stats().missCount());
+        assertEquals(2, refCountedCache.stats().hitCount());
+        assertEquals(1, refCountedCache.stats().replaceCount());
+        assertEquals(1, refCountedCache.stats().removeCount());
+    }
+
+    private void assertUsage(long usage, long activeUsage) {
+        assertEquals(usage, refCountedCache.usage().usage());
+        assertEquals(activeUsage, refCountedCache.usage().activeUsage());
+    }
+}
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTests.java b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTests.java
deleted file mode 100644
index 044e1e99627..00000000000
--- a/server/src/test/java/org/opensearch/index/store/remote/utils/cache/RefCountedCacheTests.java
+++ /dev/null
@@ -1,130 +0,0 @@
-/*
- * SPDX-License-Identifier: Apache-2.0
- *
- * The OpenSearch Contributors require contributions made to
- * this file be licensed under the Apache-2.0 license or a
- * compatible open source license.
- */
-
-package org.opensearch.index.store.remote.utils.cache;
-
-import org.junit.Before;
-import org.mockito.Mockito;
-import org.opensearch.common.cache.RemovalListener;
-import org.opensearch.test.OpenSearchTestCase;
-
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.Map;
-
-public class RefCountedCacheTests extends OpenSearchTestCase {
-    private static final long SIZE = 100;
-    private RemovalListener<String, Long> removalListener;
-
-    @Before
-    public void setUp() throws Exception {
-        super.setUp();
-        this.removalListener = Mockito.mock(RemovalListener.class);
-    }
-
-    public void testLRUCache() {
-        executeRefCountedCacheTests(new LRUCache<>(SIZE, removalListener, value -> value));
-    }
-
-    public void testSegmentedCache() {
-        executeRefCountedCacheTests(
-            SegmentedCache.<String, Long>builder()
-                .capacity(SIZE)
-                .weigher(value -> value)
-                .listener(removalListener)
-                .concurrencyLevel(1)
-                .build()
-        );
-    }
-
-    void executeRefCountedCacheTests(RefCountedCache<String, Long> refCountedCache) {
-        // basic get and put operation
-        assertNull(refCountedCache.get("1"));
-        refCountedCache.put("1", 10L);
-        assertEquals(10L, (long) refCountedCache.get("1"));
-
-        // cache usage with ref ++ and --
-        assertEquals(10L, refCountedCache.usage().usage());
-        assertEquals(0L, refCountedCache.usage().activeUsage());
-        refCountedCache.incRef("1");
-        assertEquals(10L, refCountedCache.usage().usage());
-        assertEquals(10L, refCountedCache.usage().activeUsage());
-        refCountedCache.decRef("1");
-        assertEquals(10L, refCountedCache.usage().usage());
-        assertEquals(0L, refCountedCache.usage().activeUsage());
-
-        // put all delegation
-        Map<String, Long> toPutIntoCache = new HashMap<>() {
-            {
-                put("2", 20L);
-                put("3", 30L);
-            }
-        };
-        refCountedCache.putAll(toPutIntoCache);
-        toPutIntoCache.forEach((k, v) -> { assertEquals(v, refCountedCache.get(k)); });
-        assertEquals(60L, refCountedCache.usage().usage());
-        assertEquals(0L, refCountedCache.usage().activeUsage());
-
-        // since all entries has ref count = 0 first added one will be evicted first once usage >= capacity
-        refCountedCache.put("4", 40L);
-        refCountedCache.put("5", 10L);
-        assertNull(refCountedCache.get("1"));
-        assertNull(refCountedCache.get("2"));
-        Arrays.asList("3", "4", "5").forEach(k -> assertNotNull(refCountedCache.get(k)));
-        assertEquals(80L, refCountedCache.usage().usage());
-        assertEquals(0L, refCountedCache.usage().activeUsage());
-
-        // simple compute if present when present
-        refCountedCache.computeIfPresent("3", (k, v) -> { return v + 5; });
-        assertEquals(35L, (long) refCountedCache.get("3"));
-        assertEquals(85L, refCountedCache.usage().usage());
-        assertEquals(0L, refCountedCache.usage().activeUsage());
-
-        // simple compute if present when not present
-        refCountedCache.computeIfPresent("1", (k, v) -> {
-            fail("should not reach here");
-            return v + 5;
-        });
-        assertNull(refCountedCache.get("1"));
-
-        // inc ref all entries to prevent cache evictions
-        refCountedCache.incRef("3");
-        refCountedCache.incRef("4");
-        refCountedCache.incRef("5");
-        assertEquals(85L, refCountedCache.usage().usage());
-        assertEquals(85L, refCountedCache.usage().activeUsage());
-
-        // adding cache entry while > capacity won't put entry to cache
-        refCountedCache.put("6", 15L);
-        assertNull(refCountedCache.get("6"));
-        assertEquals(85L, refCountedCache.usage().usage());
-        assertEquals(85L, refCountedCache.usage().activeUsage());
-
-        // dec ref to add 6 instead of 3
-        refCountedCache.decRef("3");
-        refCountedCache.put("6", 15L);
-        assertNull(refCountedCache.get("3"));
-        assertEquals(15L, (long) refCountedCache.get("6"));
-        assertEquals(65L, refCountedCache.usage().usage());
-        assertEquals(50L, refCountedCache.usage().activeUsage());
-
-        // check stats
-        assertEquals(4, refCountedCache.stats().evictionCount());
-        assertEquals(9, refCountedCache.stats().hitCount());
-        assertEquals(7, refCountedCache.stats().missCount());
-        assertEquals(0, refCountedCache.stats().removeCount());
-        assertEquals(1, refCountedCache.stats().replaceCount());
-
-        // remove one entry
-        refCountedCache.remove("6");
-        assertNull(refCountedCache.get("6"));
-        assertEquals(50L, refCountedCache.usage().usage());
-        assertEquals(50L, refCountedCache.usage().activeUsage());
-        assertEquals(1, refCountedCache.stats().removeCount());
-    }
-}
diff --git a/server/src/test/java/org/opensearch/index/store/remote/utils/cache/SegmentedCacheTests.java b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/SegmentedCacheTests.java
new file mode 100644
index 00000000000..4081bf4d619
--- /dev/null
+++ b/server/src/test/java/org/opensearch/index/store/remote/utils/cache/SegmentedCacheTests.java
@@ -0,0 +1,17 @@
+/*
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * The OpenSearch Contributors require contributions made to
+ * this file be licensed under the Apache-2.0 license or a
+ * compatible open source license.
+ */
+
+package org.opensearch.index.store.remote.utils.cache;
+
+public class SegmentedCacheTests extends RefCountedCacheTestCase {
+    public SegmentedCacheTests() {
+        super(
+            SegmentedCache.<String, Long>builder().capacity(CAPACITY).weigher(value -> value).listener(n -> {}).concurrencyLevel(1).build()
+        );
+    }
+}
