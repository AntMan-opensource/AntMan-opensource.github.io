package reactor.netty;
import java.io.IOException;
import java.io.InputStream;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.charset.Charset;
import java.nio.file.Path;
import java.util.Objects;
import java.util.function.Function;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.ByteBufAllocator;
import io.netty.buffer.ByteBufHolder;
import io.netty.buffer.CompositeByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.util.IllegalReferenceCountException;
import org.reactivestreams.Publisher;
import reactor.core.CoreSubscriber;
import reactor.core.Fuseable;
import reactor.core.publisher.Flux;
import reactor.core.publisher.FluxOperator;
import reactor.core.publisher.Mono;
import reactor.util.Logger;
import reactor.util.Loggers;
public class ByteBufFlux extends FluxOperator<ByteBuf, ByteBuf> {
	 public static ByteBufFlux fromInbound(Publisher<?> source) {
		return fromInbound(source, ByteBufAllocator.DEFAULT);
	}
	
	 public static ByteBufFlux fromInbound(Publisher<?> source, ByteBufAllocator allocator) {
		Objects.requireNonNull(allocator, "allocator");
		return maybeFuse(Flux.from(ReactorNetty.publisherOrScalarMap(source, bytebufExtractor)), allocator);
	}
	
	 public static ByteBufFlux fromString(Publisher<? extends String> source) {
		return fromString(source, Charset.defaultCharset(), ByteBufAllocator.DEFAULT);
	}
	
	 public static ByteBufFlux fromString(Publisher<? extends String> source, Charset charset, ByteBufAllocator allocator) {
		Objects.requireNonNull(allocator, "allocator");
		Objects.requireNonNull(charset, "charset");
		return maybeFuse( Flux.from(ReactorNetty.publisherOrScalarMap( source, s -> {
							ByteBuf buffer = allocator.buffer();
							buffer.writeCharSequence(s, charset);
							return buffer;
						})), allocator);
	}
	
	 public static ByteBufFlux fromPath(Path path) {
		return fromPath(path, MAX_CHUNK_SIZE);
	}
	
	 public static ByteBufFlux fromPath(Path path, int maxChunkSize) {
		return fromPath(path, maxChunkSize, ByteBufAllocator.DEFAULT);
	}
	
	 public static ByteBufFlux fromPath(Path path, ByteBufAllocator allocator) {
		return fromPath(path, MAX_CHUNK_SIZE, allocator);
	}
	
	 public static ByteBufFlux fromPath(Path path, int maxChunkSize, ByteBufAllocator allocator) {
		Objects.requireNonNull(path, "path");
		Objects.requireNonNull(allocator, "allocator");
		if (maxChunkSize < 1) {
			throw new IllegalArgumentException("chunk size must be strictly positive, " + "was: " + maxChunkSize);
		}
		
		return maybeFuse( Flux.generate(() -> FileChannel.open(path), (fc, sink) -> {
				                  ByteBuf buf = allocator.buffer();
				                  try {
				                      if (buf.writeBytes(fc, maxChunkSize) < 0) {
				                          buf.release();
				                          sink.complete();
				                      }
				                      
				                      else {
				                          sink.next(buf);
				                      }
				                      
				                  }
				                  
				                  catch (IOException e) {
				                      buf.release();
				                      sink.error(e);
				                  }
				                  
				                  return fc;
				              }, ReactorNetty.fileCloser), allocator);
	}
	
	 public final Flux<ByteBuffer> asByteBuffer() {
		return handle((bb, sink) -> {
			try {
				sink.next(bb.nioBuffer());
			}
			
			catch (IllegalReferenceCountException e) {
				sink.complete();
			}
			
		}
		
);
	}
	
	 public final Flux<byte[]> asByteArray() {
		return handle((bb, sink) -> {
			try {
				byte[] bytes = new byte[bb.readableBytes()];
				bb.readBytes(bytes);
				sink.next(bytes);
			}
			
			catch (IllegalReferenceCountException e) {
				sink.complete();
			}
			
		}
		
);
	}
	
	 public final Flux<InputStream> asInputStream() {
		return handle((bb, sink) -> {
			try {
				sink.next(new ByteBufMono.ReleasingInputStream(bb));
			}
			
			catch (IllegalReferenceCountException e) {
				sink.complete();
			}
			
		}
		
);
	}
	
	 public final Flux<String> asString() {
		return asString(Charset.defaultCharset());
	}
	
	 public final Flux<String> asString(Charset charset) {
		Objects.requireNonNull(charset, "charset");
		return handle((bb, sink) -> {
			try {
				sink.next(bb.readCharSequence(bb.readableBytes(), charset).toString());
			}
			
			catch (IllegalReferenceCountException e) {
				sink.complete();
			}
			
		}
		
);
	}
	
	 public final ByteBufMono aggregate() {
		return Mono.defer(() -> {
		               CompositeByteBuf output = alloc.compositeBuffer();
		               return doOnNext(ByteBuf::retain) .collectList() .doOnDiscard(ByteBuf.class, ByteBufFlux::safeRelease) .handle((list, sink) -> {
		                           if (!list.isEmpty()) {
		                               try {
		                                   output.addComponents(true, list);
		                               }
		                               
		                               catch (IllegalReferenceCountException e) {
		                                   if (log.isDebugEnabled()) {
		                                       log.debug("", e);
		                                   }
		                                   
		                               }
		                               
		                           }
		                           
		                           if (output.isReadable()) {
		                               sink.next(output);
		                           }
		                           
		                           else {
		                               sink.complete();
		                           }
		                           
		                       }
) .doFinally(signalType -> safeRelease(output));
		               }
) .as(ByteBufMono::maybeFuse);
	}
	
	public final ByteBufMono multicast() {
		throw new UnsupportedOperationException("Not yet implemented");
	}
	
	 public final ByteBufFlux retain() {
		return maybeFuse(doOnNext(ByteBuf::retain), alloc);
	}
	
	final ByteBufAllocator alloc;
	ByteBufFlux(Flux<ByteBuf> source, ByteBufAllocator allocator) {
		super(source);
		this.alloc = allocator;
	}
	
	static final class ByteBufFluxFuseable extends ByteBufFlux implements Fuseable {
		ByteBufFluxFuseable(Flux<ByteBuf> source, ByteBufAllocator allocator) {
			super(source, allocator);
		}
		
	}
	
	public void subscribe(CoreSubscriber<? super ByteBuf> s) {
		source.subscribe(s);
	}
	
	static ByteBufFlux maybeFuse(Flux<ByteBuf> source, ByteBufAllocator allocator) {
		if (source instanceof Fuseable) {
			return new ByteBufFluxFuseable(source, allocator);
		}
		
		return new ByteBufFlux(source, allocator);
	}
	
	 final static Function<Object, ByteBuf> bytebufExtractor = o -> {
		if (o instanceof ByteBuf) {
			return (ByteBuf) o;
		}
		
		if (o instanceof ByteBufHolder) {
			return ((ByteBufHolder) o).content();
		}
		
		if (o instanceof byte[]) {
			return Unpooled.wrappedBuffer((byte[]) o);
		}
		
		throw new IllegalArgumentException("Object " + o + " of type " + o.getClass() + " " + "cannot be converted to ByteBuf");
	};
	final static int MAX_CHUNK_SIZE = 1024 * 512; 
	final static Logger log = Loggers.getLogger(ByteBufFlux.class);
	static void safeRelease(ByteBuf byteBuf) {
		if (byteBuf.refCnt() > 0) {
			try {
				byteBuf.release();
			}
			
			catch (IllegalReferenceCountException e) {
				if (log.isDebugEnabled()) {
					log.debug("", e);
				}
				
			}
			
		}
		
	}
	
}


