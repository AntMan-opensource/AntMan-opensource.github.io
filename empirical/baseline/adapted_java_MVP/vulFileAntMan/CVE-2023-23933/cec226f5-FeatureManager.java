package org.opensearch.ad.feature;
import static java.util.Arrays.copyOfRange;
import static org.apache.commons.math3.linear.MatrixUtils.createRealMatrix;
import java.io.IOException;
import java.time.Clock;
import java.time.Duration;
import java.time.Instant;
import java.time.temporal.ChronoUnit;
import java.util.AbstractMap;
import java.util.AbstractMap.SimpleImmutableEntry;
import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.Deque;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Optional;
import java.util.TreeMap;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import java.util.stream.LongStream;
import java.util.stream.Stream;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.opensearch.action.ActionListener;
import org.opensearch.action.support.ThreadedActionListener;
import org.opensearch.ad.CleanState;
import org.opensearch.ad.common.exception.EndRunException;
import org.opensearch.ad.constant.CommonErrorMessages;
import org.opensearch.ad.dataprocessor.Interpolator;
import org.opensearch.ad.model.AnomalyDetector;
import org.opensearch.ad.model.Entity;
import org.opensearch.threadpool.ThreadPool;
public class FeatureManager implements CleanState {
    private static final Logger logger = LogManager.getLogger(FeatureManager.class);
    private final Map<String, ArrayDeque<Entry<Long, Optional<double[]>>>> detectorIdsToTimeShingles;
    private final SearchFeatureDao searchFeatureDao;
    private final Interpolator interpolator;
    private final Clock clock;
    private final int maxTrainSamples;
    private final int maxSampleStride;
    private final int trainSampleTimeRangeInHours;
    private final int minTrainSamples;
    private final double maxMissingPointsRate;
    private final int maxNeighborDistance;
    private final double previewSampleRate;
    private final int maxPreviewSamples;
    private final Duration featureBufferTtl;
    private final ThreadPool threadPool;
    private final String adThreadPoolName;
    public FeatureManager( SearchFeatureDao searchFeatureDao, Interpolator interpolator, Clock clock, int maxTrainSamples, int maxSampleStride, int trainSampleTimeRangeInHours, int minTrainSamples, double maxMissingPointsRate, int maxNeighborDistance, double previewSampleRate, int maxPreviewSamples, Duration featureBufferTtl, ThreadPool threadPool, String adThreadPoolName ) {
        this.searchFeatureDao = searchFeatureDao;
        this.interpolator = interpolator;
        this.clock = clock;
        this.maxTrainSamples = maxTrainSamples;
        this.maxSampleStride = maxSampleStride;
        this.trainSampleTimeRangeInHours = trainSampleTimeRangeInHours;
        this.minTrainSamples = minTrainSamples;
        this.maxMissingPointsRate = maxMissingPointsRate;
        this.maxNeighborDistance = maxNeighborDistance;
        this.previewSampleRate = previewSampleRate;
        this.maxPreviewSamples = maxPreviewSamples;
        this.featureBufferTtl = featureBufferTtl;
        this.detectorIdsToTimeShingles = new ConcurrentHashMap<>();
        this.threadPool = threadPool;
        this.adThreadPoolName = adThreadPoolName;
    }
    
    public void getCurrentFeatures(AnomalyDetector detector, long startTime, long endTime, ActionListener<SinglePointFeatures> listener) {
        int shingleSize = detector.getShingleSize();
        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles .computeIfAbsent(detector.getDetectorId(), id -> new ArrayDeque<>(shingleSize));
        long maxTimeDifference = detector.getDetectorIntervalInMilliseconds() / 2;
        Map<Long, Entry<Long, Optional<double[]>>> featuresMap = getNearbyPointsForShingle(detector, shingle, endTime, maxTimeDifference) .collect(Collectors.toMap(Entry::getKey, Entry::getValue));
        List<Entry<Long, Long>> missingRanges = getMissingRangesInShingle(detector, featuresMap, endTime);
        if (missingRanges.size() > 0) {
            try {
                searchFeatureDao.getFeatureSamplesForPeriods(detector, missingRanges, ActionListener.wrap(points -> {
                    for (int i = 0; i < points.size(); i++) {
                        Optional<double[]> point = points.get(i);
                        long rangeEndTime = missingRanges.get(i).getValue();
                        featuresMap.put(rangeEndTime, new SimpleImmutableEntry<>(rangeEndTime, point));
                    }
                    
                    updateUnprocessedFeatures(detector, shingle, featuresMap, endTime, listener);
                }, listener::onFailure));
            }
             catch (IOException e) {
                listener.onFailure(new EndRunException(detector.getDetectorId(), CommonErrorMessages.INVALID_SEARCH_QUERY_MSG, e, true));
            }
            
        }
         else {
            listener.onResponse(getProcessedFeatures(shingle, detector, endTime));
        }
        
    }
    
    private List<Entry<Long, Long>> getMissingRangesInShingle( AnomalyDetector detector, Map<Long, Entry<Long, Optional<double[]>>> featuresMap, long endTime ) {
        long intervalMilli = detector.getDetectorIntervalInMilliseconds();
        int shingleSize = detector.getShingleSize();
        return getFullShingleEndTimes(endTime, intervalMilli, shingleSize) .filter(time -> !featuresMap.containsKey(time)) .mapToObj(time -> new SimpleImmutableEntry<>(time - intervalMilli, time)) .collect(Collectors.toList());
    }
    
    private void updateUnprocessedFeatures( AnomalyDetector detector, Deque<Entry<Long, Optional<double[]>>> shingle, Map<Long, Entry<Long, Optional<double[]>>> featuresMap, long endTime, ActionListener<SinglePointFeatures> listener ) {
        shingle.clear();
        getFullShingleEndTimes(endTime, detector.getDetectorIntervalInMilliseconds(), detector.getShingleSize()) .mapToObj(time -> featuresMap.getOrDefault(time, new SimpleImmutableEntry<>(time, Optional.empty()))) .forEach(e -> shingle.add(e));
        listener.onResponse(getProcessedFeatures(shingle, detector, endTime));
    }
    
    private double[][] filterAndFill(Deque<Entry<Long, Optional<double[]>>> shingle, long endTime, AnomalyDetector detector) {
        int shingleSize = detector.getShingleSize();
        Deque<Entry<Long, Optional<double[]>>> filteredShingle = shingle .stream() .filter(e -> e.getValue().isPresent()) .collect(Collectors.toCollection(ArrayDeque::new));
        double[][] result = null;
        if (filteredShingle.size() >= shingleSize - getMaxMissingPoints(shingleSize)) {
            long maxMillisecondsDifference = maxNeighborDistance * detector.getDetectorIntervalInMilliseconds();
            result = getNearbyPointsForShingle(detector, filteredShingle, endTime, maxMillisecondsDifference) .map(e -> e.getValue().getValue().orElse(null)) .filter(d -> d != null) .toArray(double[][]::new);
            if (result.length < shingleSize) {
                result = null;
            }
            
        }
        
        return result;
    }
    
    private Stream<Entry<Long, Entry<Long, Optional<double[]>>>> getNearbyPointsForShingle( AnomalyDetector detector, Deque<Entry<Long, Optional<double[]>>> shingle, long endTime, long maxMillisecondsDifference ) {
        long intervalMilli = detector.getDetectorIntervalInMilliseconds();
        int shingleSize = detector.getShingleSize();
        TreeMap<Long, Optional<double[]>> search = new TreeMap<>( shingle.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue)) );
        return getFullShingleEndTimes(endTime, intervalMilli, shingleSize).mapToObj(t -> {
            Optional<Entry<Long, Optional<double[]>>> after = Optional.ofNullable(search.ceilingEntry(t));
            Optional<Entry<Long, Optional<double[]>>> before = Optional.ofNullable(search.floorEntry(t));
            return after .filter(a -> Math.abs(t - a.getKey()) <= before.map(b -> Math.abs(t - b.getKey())).orElse(Long.MAX_VALUE)) .map(Optional::of) .orElse(before) .filter(e -> Math.abs(t - e.getKey()) < maxMillisecondsDifference) .map(e -> new SimpleImmutableEntry<>(t, e));
        }
).filter(Optional::isPresent).map(Optional::get);
    }
    
    private LongStream getFullShingleEndTimes(long endTime, long intervalMilli, int shingleSize) {
        return LongStream.rangeClosed(1, shingleSize).map(i -> endTime - (shingleSize - i) * intervalMilli);
    }
    
    public Optional<double[][]> getColdStartData(AnomalyDetector detector) {
        int shingleSize = detector.getShingleSize();
        return searchFeatureDao .getLatestDataTime(detector) .flatMap(latest -> searchFeatureDao.getFeaturesForSampledPeriods(detector, maxTrainSamples, maxSampleStride, latest)) .map( samples -> transpose( interpolator.interpolate(transpose(samples.getKey()), samples.getValue() * (samples.getKey().length - 1) + 1) ) ) .map(points -> batchShingle(points, shingleSize));
    }
    
    public void getColdStartData(AnomalyDetector detector, ActionListener<Optional<double[][]>> listener) {
        ActionListener<Optional<Long>> latestTimeListener = ActionListener .wrap(latest -> getColdStartSamples(latest, detector, listener), listener::onFailure);
        searchFeatureDao .getLatestDataTime(detector, new ThreadedActionListener<>(logger, threadPool, adThreadPoolName, latestTimeListener, false));
    }
    
    private void getColdStartSamples(Optional<Long> latest, AnomalyDetector detector, ActionListener<Optional<double[][]>> listener) {
        int shingleSize = detector.getShingleSize();
        if (latest.isPresent()) {
            List<Entry<Long, Long>> sampleRanges = getColdStartSampleRanges(detector, latest.get());
            try {
                ActionListener<List<Optional<double[]>>> getFeaturesListener = ActionListener .wrap(samples -> processColdStartSamples(samples, shingleSize, listener), listener::onFailure);
                searchFeatureDao .getFeatureSamplesForPeriods( detector, sampleRanges, new ThreadedActionListener<>(logger, threadPool, adThreadPoolName, getFeaturesListener, false) );
            }
             catch (IOException e) {
                listener.onFailure(new EndRunException(detector.getDetectorId(), CommonErrorMessages.INVALID_SEARCH_QUERY_MSG, e, true));
            }
            
        }
         else {
            listener.onResponse(Optional.empty());
        }
        
    }
    
    private void processColdStartSamples(List<Optional<double[]>> samples, int shingleSize, ActionListener<Optional<double[][]>> listener) {
        List<double[]> shingles = new ArrayList<>();
        LinkedList<Optional<double[]>> currentShingle = new LinkedList<>();
        for (Optional<double[]> sample : samples) {
            currentShingle.addLast(sample);
            if (currentShingle.size() == shingleSize) {
                sample.ifPresent(s -> fillAndShingle(currentShingle, shingleSize).ifPresent(shingles::add));
                currentShingle.remove();
            }
            
        }
        
        listener.onResponse(Optional.of(shingles.toArray(new double[0][0])).filter(results -> results.length > 0));
    }
    
    private Optional<double[]> fillAndShingle(LinkedList<Optional<double[]>> shingle, int shingleSize) {
        Optional<double[]> result = null;
        if (shingle.stream().filter(s -> s.isPresent()).count() >= shingleSize - getMaxMissingPoints(shingleSize)) {
            TreeMap<Integer, double[]> search = new TreeMap<>( IntStream .range(0, shingleSize) .filter(i -> shingle.get(i).isPresent()) .boxed() .collect(Collectors.toMap(i -> i, i -> shingle.get(i).get())) );
            result = Optional.of(IntStream.range(0, shingleSize).mapToObj(i -> {
                Optional<Entry<Integer, double[]>> after = Optional.ofNullable(search.ceilingEntry(i));
                Optional<Entry<Integer, double[]>> before = Optional.ofNullable(search.floorEntry(i));
                return after .filter(a -> Math.abs(i - a.getKey()) <= before.map(b -> Math.abs(i - b.getKey())).orElse(Integer.MAX_VALUE)) .map(Optional::of) .orElse(before) .filter(e -> Math.abs(i - e.getKey()) <= maxNeighborDistance) .map(Entry::getValue) .orElse(null);
            }
).filter(d -> d != null).toArray(double[][]::new)) .filter(d -> d.length == shingleSize) .map(d -> batchShingle(d, shingleSize)[0]);
        }
         else {
            result = Optional.empty();
        }
        
        return result;
    }
    
    private List<Entry<Long, Long>> getColdStartSampleRanges(AnomalyDetector detector, long endMillis) {
        long interval = detector.getDetectorIntervalInMilliseconds();
        int numSamples = Math.max((int) (Duration.ofHours(this.trainSampleTimeRangeInHours).toMillis() / interval), this.minTrainSamples);
        return IntStream .rangeClosed(1, numSamples) .mapToObj(i -> new SimpleImmutableEntry<>(endMillis - (numSamples - i + 1) * interval, endMillis - (numSamples - i) * interval)) .collect(Collectors.toList());
    }
    
    public double[][] batchShingle(double[][] points, int shingleSize) {
        if (points.length == 0 || points[0].length == 0 || points.length < shingleSize || shingleSize < 1) {
            throw new IllegalArgumentException("Invalid data for shingling.");
        }
        
        int numPoints = points.length;
        int dimPoint = points[0].length;
        int numShingles = numPoints - shingleSize + 1;
        int dimShingle = dimPoint * shingleSize;
        double[][] shingles = new double[numShingles][dimShingle];
        for (int i = 0; i < numShingles; i++) {
            for (int j = 0; j < shingleSize; j++) {
                System.arraycopy(points[i + j], 0, shingles[i], j * dimPoint, dimPoint);
            }
            
        }
        
        return shingles;
    }
    
    public void clear(String detectorId) {
        detectorIdsToTimeShingles.remove(detectorId);
    }
    
    public void maintenance() {
        try {
            detectorIdsToTimeShingles .entrySet() .removeIf( idQueue -> Optional .ofNullable(idQueue.getValue().peekLast()) .map(p -> Instant.ofEpochMilli(p.getKey()).plus(featureBufferTtl).isBefore(clock.instant())) .orElse(true) );
        }
         catch (Exception e) {
            logger.warn("Caught exception during maintenance", e);
        }
        
    }
    
    public void getPreviewEntities(AnomalyDetector detector, long startTime, long endTime, ActionListener<List<Entity>> listener) {
        searchFeatureDao.getHighestCountEntities(detector, startTime, endTime, listener);
    }
    
    public void getPreviewFeaturesForEntity( AnomalyDetector detector, Entity entity, long startMilli, long endMilli, ActionListener<Features> listener ) throws IOException {
        Entry<List<Entry<Long, Long>>, Integer> sampleRangeResults = getSampleRanges(detector, startMilli, endMilli);
        List<Entry<Long, Long>> sampleRanges = sampleRangeResults.getKey();
        int stride = sampleRangeResults.getValue();
        int shingleSize = detector.getShingleSize();
        getSamplesInRangesForEntity(detector, sampleRanges, entity, getFeatureSamplesListener(stride, shingleSize, listener));
    }
    
    private ActionListener<Entry<List<Entry<Long, Long>>, double[][]>> getFeatureSamplesListener( int stride, int shingleSize, ActionListener<Features> listener ) {
        return ActionListener.wrap(samples -> {
            List<Entry<Long, Long>> searchTimeRange = samples.getKey();
            if (searchTimeRange.size() == 0) {
                listener.onFailure(new IllegalArgumentException("No data to preview anomaly detection."));
                return;
            }
            
            double[][] sampleFeatures = samples.getValue();
            List<Entry<Long, Long>> previewRanges = getPreviewRanges(searchTimeRange, stride, shingleSize);
            Entry<double[][], double[][]> previewFeatures = getPreviewFeatures(sampleFeatures, stride, shingleSize);
            listener.onResponse(new Features(previewRanges, previewFeatures.getKey(), previewFeatures.getValue()));
        }, listener::onFailure);
    }
    
    public void getPreviewFeatures(AnomalyDetector detector, long startMilli, long endMilli, ActionListener<Features> listener) throws IOException {
        Entry<List<Entry<Long, Long>>, Integer> sampleRangeResults = getSampleRanges(detector, startMilli, endMilli);
        List<Entry<Long, Long>> sampleRanges = sampleRangeResults.getKey();
        int stride = sampleRangeResults.getValue();
        int shingleSize = detector.getShingleSize();
        getSamplesForRanges(detector, sampleRanges, getFeatureSamplesListener(stride, shingleSize, listener));
    }
    
    private Entry<List<Entry<Long, Long>>, Integer> getSampleRanges(AnomalyDetector detector, long startMilli, long endMilli) {
        long start = truncateToMinute(startMilli);
        long end = truncateToMinute(endMilli);
        long bucketSize = detector.getDetectorIntervalInMilliseconds();
        int numBuckets = (int) Math.floor((end - start) / (double) bucketSize);
        int numSamples = (int) Math.max(Math.min(numBuckets * previewSampleRate, maxPreviewSamples), 1);
        int stride = (int) Math.max(1, Math.floor((double) numBuckets / numSamples));
        int numStrides = (int) Math.ceil(numBuckets / (double) stride);
        List<Entry<Long, Long>> sampleRanges = Stream .iterate(start, i -> i + stride * bucketSize) .limit(numStrides) .map(time -> new SimpleImmutableEntry<>(time, time + bucketSize)) .collect(Collectors.toList());
        return new SimpleImmutableEntry<>(sampleRanges, stride);
    }
    
    void getSamplesInRangesForEntity( AnomalyDetector detector, List<Entry<Long, Long>> sampleRanges, Entity entity, ActionListener<Entry<List<Entry<Long, Long>>, double[][]>> listener ) throws IOException {
        searchFeatureDao .getColdStartSamplesForPeriods(detector, sampleRanges, entity, true, getSamplesRangesListener(sampleRanges, listener));
    }
    
    private ActionListener<List<Optional<double[]>>> getSamplesRangesListener( List<Entry<Long, Long>> sampleRanges, ActionListener<Entry<List<Entry<Long, Long>>, double[][]>> listener ) {
        return ActionListener.wrap(featureSamples -> {
            List<Entry<Long, Long>> ranges = new ArrayList<>(featureSamples.size());
            List<double[]> samples = new ArrayList<>(featureSamples.size());
            for (int i = 0; i < featureSamples.size(); i++) {
                Entry<Long, Long> currentRange = sampleRanges.get(i);
                featureSamples.get(i).ifPresent(sample -> {
                    ranges.add(currentRange);
                    samples.add(sample);
                }
                
);
            }
            
            listener.onResponse(new SimpleImmutableEntry<>(ranges, samples.toArray(new double[0][0])));
        }, listener::onFailure);
    }
    
    void getSamplesForRanges( AnomalyDetector detector, List<Entry<Long, Long>> sampleRanges, ActionListener<Entry<List<Entry<Long, Long>>, double[][]>> listener ) throws IOException {
        searchFeatureDao.getFeatureSamplesForPeriods(detector, sampleRanges, getSamplesRangesListener(sampleRanges, listener));
    }
    
    private List<Entry<Long, Long>> getPreviewRanges(List<Entry<Long, Long>> ranges, int stride, int shingleSize) {
        double[] rangeStarts = ranges.stream().mapToDouble(Entry::getKey).toArray();
        double[] rangeEnds = ranges.stream().mapToDouble(Entry::getValue).toArray();
        double[] previewRangeStarts = interpolator.interpolate(new double[][] { rangeStarts }, stride * (ranges.size() - 1) + 1)[0];
        double[] previewRangeEnds = interpolator.interpolate(new double[][] { rangeEnds }, stride * (ranges.size() - 1) + 1)[0];
        List<Entry<Long, Long>> previewRanges = IntStream .range(shingleSize - 1, previewRangeStarts.length) .mapToObj(i -> new SimpleImmutableEntry<>((long) previewRangeStarts[i], (long) previewRangeEnds[i])) .collect(Collectors.toList());
        return previewRanges;
    }
    
    private Entry<double[][], double[][]> getPreviewFeatures(double[][] samples, int stride, int shingleSize) {
        Entry<double[][], double[][]> unprocessedAndProcessed = Optional .of(samples) .map(m -> transpose(m)) .map(m -> interpolator.interpolate(m, stride * (samples.length - 1) + 1)) .map(m -> transpose(m)) .map(m -> new SimpleImmutableEntry<>(copyOfRange(m, shingleSize - 1, m.length), batchShingle(m, shingleSize))) .get();
        return unprocessedAndProcessed;
    }
    
    public double[][] transpose(double[][] matrix) {
        return createRealMatrix(matrix).transpose().getData();
    }
    
    private long truncateToMinute(long epochMillis) {
        return Instant.ofEpochMilli(epochMillis).truncatedTo(ChronoUnit.MINUTES).toEpochMilli();
    }
    
    private int getMaxMissingPoints(int shingleSize) {
        return (int) Math.floor(shingleSize * maxMissingPointsRate);
    }
    
    public int getShingleSize(String detectorId) {
        Deque<Entry<Long, Optional<double[]>>> shingle = detectorIdsToTimeShingles.get(detectorId);
        if (shingle != null) {
            return Math.toIntExact(shingle.stream().filter(entry -> entry.getValue().isPresent()).count());
        }
         else {
            return -1;
        }
        
    }
    
    public void getFeatureDataPointsByBatch( AnomalyDetector detector, Entity entity, long startTime, long endTime, ActionListener<Map<Long, Optional<double[]>>> listener ) {
        try {
            searchFeatureDao.getFeaturesForPeriodByBatch(detector, entity, startTime, endTime, ActionListener.wrap(points -> {
                logger.debug("features size: {}", points.size());
                listener.onResponse(points);
            }, listener::onFailure));
        }
         catch (Exception e) {
            logger.error("Failed to get features for detector: " + detector.getDetectorId());
            listener.onFailure(e);
        }
        
    }
    
    public SinglePointFeatures getShingledFeatureForHistoricalAnalysis( AnomalyDetector detector, Deque<Entry<Long, Optional<double[]>>> shingle, Optional<double[]> dataPoint, long endTime ) {
        while (shingle.size() >= detector.getShingleSize()) {
            shingle.poll();
        }
        
        shingle.add(new AbstractMap.SimpleEntry<>(endTime, dataPoint));
        return getProcessedFeatures(shingle, detector, endTime);
    }
    
    private SinglePointFeatures getProcessedFeatures( Deque<Entry<Long, Optional<double[]>>> shingle, AnomalyDetector detector, long endTime ) {
        int shingleSize = detector.getShingleSize();
        Optional<double[]> currentPoint = shingle.peekLast().getValue();
        return new SinglePointFeatures( currentPoint, Optional .ofNullable(currentPoint.isPresent() ? filterAndFill(shingle, endTime, detector) : null) .map(points -> batchShingle(points, shingleSize)[0]) );
    }
    
}


